{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer (Ko-En) 번역기 v2.0\n",
    "---\n",
    "### 프로젝트 목표\n",
    "한국어-영어 번역을 위한 트랜스포머 모델에 메캅 형태소 분석 추가\n",
    "\n",
    "**주요 변경 사항 (v1.3 대비):**\n",
    "1. 데이터 증강: NLLB 모델을 활용한 역번역(Back-translation) 기법을 도입하여 학습 데이터의 양과 질을 대폭 향상.\n",
    "2. 토크나이저: 한국어 토큰화 시, `Mecab` 형태소 분석기를 `SentencePiece` 이전에 적용하여 언어적 특성 반영을 강화.\n",
    "3. 훈련 방식 업그레이드:\n",
    "    - 옵티마이저: Adam -> AdamW로 변경하고 `weight_decay`를 적용하여 정규화 성능 개선.\n",
    "    - 손실 함수: `Label Smoothing`을 적용하여 모델의 과신을 방지하고 일반화 성능 향상.\n",
    "    - 학습률 스케줄러: `역제곱근 감쇠` 방식 (All You Need is Attention 논문 방식)-> '코사인 어닐링' 방식으로 변경하여 더 안정적인 수렴 유도.\n",
    "4. 평가 방식: 빔 서치(Beam Search) 디코딩을 기본으로 사용하고, BLEU, METEOR, ROUGE, BERTScore를 모두 측정하는 종합 평가 파이프라인 구축."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 설치 및 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece\n",
    "!pip install gensim\n",
    "!pip install nltk\n",
    "!pip install konlpy\n",
    "!pip install transformers\n",
    "!pip install rouge-score bert-score\n",
    "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
    "%cd Mecab-ko-for-Google-Colab/\n",
    "!bash install_mecab-ko_on_colab_light_220429.sh\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import locale\n",
    "\n",
    "# 데이터 처리 및 연산\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import pipeline\n",
    "\n",
    "# 자연어 처리(NLP) 및 머신러닝\n",
    "import sentencepiece as spm\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# 시각화 및 진행률 표시\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"모든 랜덤 시드를 고정하여 재현성을 보장합니다.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) # for multi-GPU\n",
    "\n",
    "# 사용할 시드 값 설정\n",
    "SEED = 14\n",
    "set_seed(SEED)\n",
    "\n",
    "print(f\"Random seed set to {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 하이퍼파라미터 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "SRC_VOCAB_SIZE = 20000\n",
    "TGT_VOCAB_SIZE = 20000\n",
    "D_MODEL = 512\n",
    "N_LAYERS = 4\n",
    "N_HEADS = 8\n",
    "D_FF = 4096\n",
    "DROPOUT = 0.15\n",
    "MAX_LEN = 50\n",
    "\n",
    "# Training Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "EARLY_STOPPING_PATIENCE = 3\n",
    "CHECKPOINT_PATH = \"transformer-2.0-checkpoint.pth\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 준비 및 전처리 & 증강 (역번역)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 경로 설정\n",
    "data_dir = 'data'\n",
    "train_kor_path = os.path.join(data_dir, 'korean-english-park.train.ko')\n",
    "train_eng_path = os.path.join(data_dir, 'korean-english-park.train.en')\n",
    "dev_kor_path = os.path.join(data_dir, 'korean-english-park.dev.ko')\n",
    "dev_eng_path = os.path.join(data_dir, 'korean-english-park.dev.en')\n",
    "test_kor_path = os.path.join(data_dir, 'korean-english-park.test.ko')\n",
    "test_eng_path = os.path.join(data_dir, 'korean-english-park.test.en')\n",
    "\n",
    "# 2. 원본 데이터 로딩\n",
    "with open(train_kor_path, \"r\", encoding='utf-8') as f: train_kor_raw = f.read().splitlines()\n",
    "with open(train_eng_path, \"r\", encoding='utf-8') as f: train_eng_raw = f.read().splitlines()\n",
    "with open(dev_kor_path, \"r\", encoding='utf-8') as f: dev_kor_raw = f.read().splitlines()\n",
    "with open(dev_eng_path, \"r\", encoding='utf-8') as f: dev_eng_raw = f.read().splitlines()\n",
    "with open(test_kor_path, \"r\", encoding='utf-8') as f: test_kor_raw = f.read().splitlines()\n",
    "with open(test_eng_path, \"r\", encoding='utf-8') as f: test_eng_raw = f.read().splitlines()\n",
    "\n",
    "print(f\"Train: {len(train_kor_raw)}, Dev: {len(dev_kor_raw)}, Test: {len(test_kor_raw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLLB 모델 로드 (GPU 사용)\n",
    "translator = pipeline(\n",
    "    'translation',\n",
    "    model='facebook/nllb-200-distilled-600M',\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "def back_translate_nllb_optimized(sentences, chunk_size=1000, batch_size=32):\n",
    "    \"\"\"\n",
    "    역번역을 진행하면서 진행 상황을 출력하고, 효율성을 높이는 함수.\n",
    "    Args:\n",
    "        sentences (list): 역번역할 한국어 문장 리스트.\n",
    "        chunk_size (int): 진행 상황을 출력할 단위.\n",
    "        batch_size (int): 모델 추론 시 사용할 배치 크기 (GPU 효율성 향상).\n",
    "    Returns:\n",
    "        list: 역번역된 문장 리스트.\n",
    "    \"\"\"\n",
    "    augmented_sentences = []\n",
    "    total_sentences = len(sentences)\n",
    "    \n",
    "    print(f\"총 {total_sentences}개의 문장을 역번역합니다...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 데이터를 청크 단위로 분할하여 처리\n",
    "    for i in range(0, total_sentences, chunk_size):\n",
    "        chunk_start = i\n",
    "        chunk_end = min(i + chunk_size, total_sentences)\n",
    "        \n",
    "        # 한국어 -> 영어 번역 (배치 크기 적용)\n",
    "        translated_to_en = [\n",
    "            result['translation_text'] for result in translator(sentences[chunk_start:chunk_end], \n",
    "                                                               src_lang='kor_Hang', \n",
    "                                                               tgt_lang='eng_Latn',\n",
    "                                                               batch_size=batch_size) # 배치 크기 인자 추가\n",
    "        ]\n",
    "        \n",
    "        # 영어 -> 한국어 역번역 (배치 크기 적용)\n",
    "        back_translated_to_ko = [\n",
    "            result['translation_text'] for result in translator(translated_to_en, \n",
    "                                                               src_lang='eng_Latn', \n",
    "                                                               tgt_lang='kor_Hang',\n",
    "                                                               batch_size=batch_size) # 배치 크기 인자 추가\n",
    "        ]\n",
    "        \n",
    "        augmented_sentences.extend(back_translated_to_ko)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"[{chunk_end}/{total_sentences}] 문장 처리 완료 | 경과 시간: {elapsed_time:.2f}초\")\n",
    "\n",
    "    return augmented_sentences\n",
    "\n",
    "# 최적화된 함수 사용\n",
    "print(\"\\n한국어 학습 데이터 역번역을 시작합니다...\")\n",
    "augmented_train_kor_raw = back_translate_nllb_optimized(train_kor_raw)\n",
    "print(\"데이터 증강 완료\")\n",
    "\n",
    "# 원본 데이터와 증강된 데이터를 합치기\n",
    "combined_train_kor_raw = train_kor_raw + augmented_train_kor_raw\n",
    "combined_train_eng_raw = train_eng_raw + train_eng_raw\n",
    "\n",
    "print(f\"최종 학습 데이터 크기: 한국어 {len(combined_train_kor_raw)}, 영어 {len(combined_train_eng_raw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 데이터 정제 및 전처리\n",
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"구두점, 특수문자 등 불필요한 부분을 제거하고 소문자로 변환합니다.\"\"\"\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z가-힣?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "def clean_and_preprocess_corpus(kor_raw, eng_raw):\n",
    "    \"\"\"문장 쌍의 중복을 제거하고 각 문장을 전처리합니다.\"\"\"\n",
    "    # 1. zip으로 문장 쌍 생성 후 set으로 중복 제거\n",
    "    cleaned_pairs = list(set(zip(kor_raw, eng_raw)))\n",
    "\n",
    "    # 2. 각 문장 전처리\n",
    "    kor_corpus, eng_corpus = [], []\n",
    "    for kor, eng in cleaned_pairs:\n",
    "        kor_corpus.append(preprocess_sentence(kor))\n",
    "        eng_corpus.append(preprocess_sentence(eng))\n",
    "\n",
    "    return kor_corpus, eng_corpus\n",
    "\n",
    "# 각 데이터셋에 대해 정제 및 전처리 수행\n",
    "train_kor_corpus, train_eng_corpus = clean_and_preprocess_corpus(combined_train_kor_raw, combined_train_eng_raw)\n",
    "dev_kor_corpus, dev_eng_corpus = clean_and_preprocess_corpus(dev_kor_raw, dev_eng_raw)\n",
    "test_kor_corpus, test_eng_corpus = clean_and_preprocess_corpus(test_kor_raw, test_eng_raw)\n",
    "\n",
    "print(f\"Train: {len(train_kor_corpus)}, Dev: {len(dev_kor_corpus)}, Test: {len(test_kor_corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "# 1. Mecab 초기화\n",
    "mecab = Mecab()\n",
    "def mecab_tokenize_corpus(corpus):\n",
    "    mecab_corpus = []\n",
    "    for sentence in corpus:\n",
    "        # 형태소 분리 후 공백으로 join\n",
    "        morphs = mecab.morphs(sentence)\n",
    "        mecab_corpus.append(\" \".join(morphs))\n",
    "    return mecab_corpus\n",
    "\n",
    "# 2. 한국어 데이터셋 Mecab 처리\n",
    "train_kor_mecab = mecab_tokenize_corpus(train_kor_corpus)\n",
    "dev_kor_mecab   = mecab_tokenize_corpus(dev_kor_corpus)\n",
    "test_kor_mecab  = mecab_tokenize_corpus(test_kor_corpus)\n",
    "\n",
    "print(\"Before:\", train_kor_corpus[0])\n",
    "print(\"After :\", train_kor_mecab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tokenizer(corpus, vocab_size, lang, pad_id=0, bos_id=1, eos_id=2, unk_id=3):\n",
    "    file = f'./{lang}_corpus.txt'\n",
    "    model_prefix = f'{lang}_spm'\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        for row in corpus:\n",
    "            f.write(str(row) + '\\n')\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f'--input={file} --model_prefix={model_prefix} --vocab_size={vocab_size}' + \n",
    "        f' --pad_id={pad_id} --bos_id={bos_id} --eos_id={eos_id} --unk_id={unk_id}'\n",
    "    )\n",
    "    tokenizer = spm.SentencePieceProcessor()\n",
    "    tokenizer.Load(f'{model_prefix}.model')\n",
    "    return tokenizer\n",
    "\n",
    "ko_tokenizer = generate_tokenizer(train_kor_mecab, SRC_VOCAB_SIZE, \"ko\")\n",
    "en_tokenizer = generate_tokenizer(train_eng_corpus, TGT_VOCAB_SIZE, \"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터셋 및 DataLoader 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_corpus, tgt_corpus, src_tokenizer, tgt_tokenizer):\n",
    "        self.src_corpus = src_corpus\n",
    "        self.tgt_corpus = tgt_corpus\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_corpus)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.src_tokenizer.encode_as_ids(self.src_corpus[idx])\n",
    "        tgt = self.tgt_tokenizer.encode_as_ids(self.tgt_corpus[idx])\n",
    "\n",
    "        # 텐서의 데이터 타입을 torch.long으로 명시적으로 지정합니다.\n",
    "        return torch.tensor(src, dtype=torch.long), torch.tensor(tgt, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"배치 내의 시퀀스들을 패딩하여 동일한 길이로 만듭니다.\"\"\"\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(src_sample)\n",
    "        tgt_batch.append(tgt_sample)\n",
    "\n",
    "    src_padded = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=ko_tokenizer.pad_id())\n",
    "    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=en_tokenizer.pad_id())\n",
    "    return src_padded, tgt_padded\n",
    "\n",
    "# Dataset 및 DataLoader 인스턴스 생성\n",
    "train_dataset = TranslationDataset(train_kor_mecab, train_eng_corpus, ko_tokenizer, en_tokenizer)\n",
    "valid_dataset = TranslationDataset(dev_kor_mecab, dev_eng_corpus, ko_tokenizer, en_tokenizer)\n",
    "test_dataset = TranslationDataset(test_kor_mecab, test_eng_corpus, ko_tokenizer, en_tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=4)\n",
    "\n",
    "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
    "print(f\"Number of batches in valid_loader: {len(valid_loader)}\")\n",
    "print(f\"Number of batches in test_loader: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 트랜스포머 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    입력 임베딩에 위치 정보를 추가하는 클래스입니다.\n",
    "    Transformer 모델은 순서 정보가 없으므로, 토큰의 위치를 알려주기 위해 sin/cos 함수를 사용합니다.\n",
    "    이 방식은 고정 위치 인코딩으로, 학습되지 않는 파라미터(buffer)로 등록됩니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # sin/cos 함수에 사용할 div_term 계산: 주파수 조절을 위한 값\n",
    "        div_term = torch.exp(torch.arange(0, emb_size, 2) * (-math.log(10000.0) / emb_size))\n",
    "        # 각 위치(0~maxlen)에 대한 인덱스 생성\n",
    "        position = torch.arange(maxlen).unsqueeze(1)\n",
    "        # 위치 임베딩 행렬 초기화 (maxlen, emb_size)\n",
    "        pos_embedding = torch.zeros(maxlen, emb_size)\n",
    "        # 짝수 인덱스: sin 함수 적용\n",
    "        pos_embedding[:, 0::2] = torch.sin(position * div_term)\n",
    "        # 홀수 인덱스: cos 함수 적용\n",
    "        pos_embedding[:, 1::2] = torch.cos(position * div_term)\n",
    "        # 배치 차원 추가 (1, maxlen, emb_size)\n",
    "        pos_embedding = pos_embedding.unsqueeze(0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 학습되지 않는 파라미터로 등록\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_embedding: (batch_size, seq_len, emb_size)\n",
    "        Returns:\n",
    "            token_embedding + pos_embedding: 위치 정보가 더해진 임베딩\n",
    "        \"\"\"\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:, :token_embedding.size(1), :])\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    다중 헤드 어텐션 메커니즘을 구현한 클래스.\n",
    "    쿼리, 키, 값 행렬을 여러 헤드로 분할하여 병렬로 어텐션을 계산하고, 결과를 결합합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.depth = d_model // num_heads  # 각 헤드의 차원\n",
    "        # 쿼리, 키, 값 행렬을 위한 선형 변환 레이어\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        # 최종 출력 선형 변환 레이어\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        \"\"\"\n",
    "        스케일드 닷-프로덕트 어텐션 계산.\n",
    "        Args:\n",
    "            Q: 쿼리 행렬\n",
    "            K: 키 행렬\n",
    "            V: 값 행렬\n",
    "            mask: 어텐션 마스크 (선택적)\n",
    "        Returns:\n",
    "            out: 어텐션 가중치 적용된 값 행렬\n",
    "            attentions: 어텐션 가중치 행렬\n",
    "        \"\"\"\n",
    "        d_k = Q.size(-1)\n",
    "        QK = torch.matmul(Q, K.transpose(-1, -2))  # QK^T 계산\n",
    "        scaled_qk = QK / math.sqrt(d_k)  # 스케일링\n",
    "        if mask is not None:\n",
    "            scaled_qk += (mask * -1e9)  # 마스크 적용 (매우 작은 값 더하기)\n",
    "        attentions = nn.Softmax(dim=-1)(scaled_qk)  # 소프트맥스 적용\n",
    "        out = torch.matmul(attentions, V)  # 가중치 적용\n",
    "        return out, attentions\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        \"\"\"\n",
    "        입력 텐서를 여러 헤드로 분할.\n",
    "        Args:\n",
    "            x: (batch_size, seq_len, d_model)\n",
    "        Returns:\n",
    "            x: (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        bsz, seq_len, _ = x.size()\n",
    "        x = x.view(bsz, seq_len, self.num_heads, self.depth)\n",
    "        return x.permute(0, 2, 1, 3)  # 차원 재배치\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        \"\"\"\n",
    "        분할된 헤드를 다시 결합.\n",
    "        Args:\n",
    "            x: (batch_size, num_heads, seq_len, depth)\n",
    "        Returns:\n",
    "            x: (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        bsz, _, seq_len, _ = x.size()\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        return x.view(bsz, seq_len, self.d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            Q: 쿼리 입력 (batch_size, seq_len, d_model)\n",
    "            K: 키 입력\n",
    "            V: 값 입력\n",
    "            mask: 어텐션 마스크\n",
    "        Returns:\n",
    "            out: 어텐션 적용된 출력\n",
    "            attention_weights: 어텐션 가중치\n",
    "        \"\"\"\n",
    "        # 헤드 분할 후 어텐션 계산\n",
    "        WQ = self.split_heads(self.W_q(Q))\n",
    "        WK = self.split_heads(self.W_k(K))\n",
    "        WV = self.split_heads(self.W_v(V))\n",
    "        out, attention_weights = self.scaled_dot_product_attention(WQ, WK, WV, mask)\n",
    "        # 헤드 결합 후 선형 변환\n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "        return out, attention_weights\n",
    "\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    \"\"\"\n",
    "    포지션 와이즈 피드포워드 네트워크.\n",
    "    각 위치별로 독립적으로 적용되는 2층 완전 연결 네트워크 (ReLU 활성화 함수 사용).\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)  # 첫 번째 레이어 (차원 확장)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)  # 두 번째 레이어 (원래 차원으로 복원)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch_size, seq_len, d_model)\n",
    "        Returns:\n",
    "            x: (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    인코더의 단일 레이어.\n",
    "    셀프 어텐션과 피드포워드 네트워크를 포함하며, 레이어 정규화와 드롭아웃을 적용합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "        self.norm_1 = nn.LayerNorm(d_model, eps=1e-6)  # 첫 번째 정규화\n",
    "        self.norm_2 = nn.LayerNorm(d_model, eps=1e-6)  # 두 번째 정규화\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: 입력 텐서\n",
    "            mask: 패딩 마스크\n",
    "        Returns:\n",
    "            out: 출력 텐서\n",
    "            enc_attn: 셀프 어텐션 가중치\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        # 셀프 어텐션 + 드롭아웃 + 잔차 연결\n",
    "        out, enc_attn = self.enc_self_attn(self.norm_1(x), self.norm_1(x), self.norm_1(x), mask)\n",
    "        out = self.do(out) + residual\n",
    "        residual = out\n",
    "        # 피드포워드 네트워크 + 드롭아웃 + 잔차 연결\n",
    "        out = self.ffn(self.norm_2(out))\n",
    "        out = self.do(out) + residual\n",
    "        return out, enc_attn\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    디코더의 단일 레이어.\n",
    "    셀프 어텐션, 인코더-디코더 어텐션, 피드포워드 네트워크를 포함합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)  # 셀프 어텐션\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)  # 인코더-디코더 어텐션\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "        self.norm_1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.norm_2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.norm_3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: 디코더 입력\n",
    "            enc_out: 인코더 출력\n",
    "            dec_enc_mask: 디코더-인코더 어텐션 마스크\n",
    "            padding_mask: 패딩 마스크\n",
    "        Returns:\n",
    "            out: 출력 텐서\n",
    "            dec_attn: 셀프 어텐션 가중치\n",
    "            dec_enc_attn: 인코더-디코더 어텐션 가중치\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        # 셀프 어텐션 (look-ahead 마스크 적용)\n",
    "        out, dec_attn = self.dec_self_attn(self.norm_1(x), self.norm_1(x), self.norm_1(x), mask=padding_mask)\n",
    "        out = self.do(out) + residual\n",
    "        residual = out\n",
    "        # 인코더-디코더 어텐션\n",
    "        out, dec_enc_attn = self.enc_dec_attn(self.norm_2(out), enc_out, enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out) + residual\n",
    "        residual = out\n",
    "        # 피드포워드 네트워크\n",
    "        out = self.ffn(self.norm_3(out))\n",
    "        out = self.do(out) + residual\n",
    "        return out, dec_attn, dec_enc_attn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    인코더 전체 구조.\n",
    "    임베딩 레이어, 위치 인코딩, 여러 개의 인코더 레이어로 구성됩니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_layers, d_model, n_heads, d_ff, dropout, vocab_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)  # 토큰 임베딩\n",
    "        self.pos_encoding = PositionalEncoding(d_model, dropout)  # 위치 인코딩\n",
    "        self.enc_layers = nn.ModuleList([EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: 입력 시퀀스 (batch_size, seq_len)\n",
    "            mask: 패딩 마스크\n",
    "        Returns:\n",
    "            out: 인코더 출력\n",
    "            enc_attns: 각 레이어의 어텐션 가중치 리스트\n",
    "        \"\"\"\n",
    "        out = self.embedding(x) * math.sqrt(self.d_model)  # 임베딩 스케일링\n",
    "        out = self.pos_encoding(out)  # 위치 인코딩 추가\n",
    "        enc_attns = []\n",
    "        for layer in self.enc_layers:\n",
    "            out, enc_attn = layer(out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        return out, enc_attns\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    디코더 전체 구조.\n",
    "    임베딩 레이어, 위치 인코딩, 여러 개의 디코더 레이어로 구성됩니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_layers, d_model, n_heads, d_ff, dropout, vocab_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, dropout)\n",
    "        self.dec_layers = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: 디코더 입력 시퀀스\n",
    "            enc_out: 인코더 출력\n",
    "            dec_enc_mask: 디코더-인코더 어텐션 마스크\n",
    "            padding_mask: 패딩 마스크\n",
    "        Returns:\n",
    "            out: 디코더 출력\n",
    "            dec_attns: 셀프 어텐션 가중치 리스트\n",
    "            dec_enc_attns: 인코더-디코더 어텐션 가중치 리스트\n",
    "        \"\"\"\n",
    "        out = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        out = self.pos_encoding(out)\n",
    "        dec_attns, dec_enc_attns = [], []\n",
    "        for layer in self.dec_layers:\n",
    "            out, dec_attn, dec_enc_attn = layer(out, enc_out, dec_enc_mask, padding_mask)\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "        return out, dec_attns, dec_enc_attns\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    전체 Transformer 모델.\n",
    "    인코더와 디코더를 연결하고, 최종 출력 레이어를 포함합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_layers, d_model, n_heads, d_ff, src_vocab_size, tgt_vocab_size, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout, src_vocab_size)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout, tgt_vocab_size)\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)  # 최종 출력 레이어\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: 소스 시퀀스 (batch_size, src_seq_len)\n",
    "            tgt: 타겟 시퀀스 (batch_size, tgt_seq_len)\n",
    "        Returns:\n",
    "            logits: 최종 예측 로짓 (batch_size, tgt_seq_len, tgt_vocab_size)\n",
    "            enc_attns: 인코더 어텐션 가중치 리스트\n",
    "            dec_attns: 디코더 셀프 어텐션 가중치 리스트\n",
    "            dec_enc_attns: 디코더-인코더 어텐션 가중치 리스트\n",
    "        \"\"\"\n",
    "        # 마스크 생성\n",
    "        src_mask = (src == ko_tokenizer.pad_id()).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt == en_tokenizer.pad_id()).unsqueeze(1).unsqueeze(2)\n",
    "        lookahead_mask = torch.triu(torch.ones(tgt.shape[1], tgt.shape[1]), diagonal=1).bool().to(device)\n",
    "        tgt_mask = tgt_mask | lookahead_mask\n",
    "        # 인코더/디코더 순전파\n",
    "        enc_out, enc_attns = self.encoder(src, src_mask)\n",
    "        dec_out, dec_attns, dec_enc_attns = self.decoder(tgt, enc_out, src_mask, tgt_mask)\n",
    "        logits = self.fc(dec_out)\n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLearningRateScheduler:\n",
    "    \"\"\"\n",
    "    \"Attention Is All You Need\" 논문에서 제안된 custom learning rate scheduler.\n",
    "    Warm-up 기간 동안 학습률을 선형적으로 증가시킨 후, step 수의 역제곱근에 비례하여 감소시킵니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, d_model, warmup_steps=4000):\n",
    "        self.optimizer = optimizer\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.num_steps = 0\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"학습률을 업데이트합니다.\"\"\"\n",
    "        self.num_steps += 1\n",
    "        lr = self._get_lr()\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def _get_lr(self):\n",
    "        \"\"\"학습률을 계산합니다.\"\"\"\n",
    "        step = self.num_steps\n",
    "        # 수식: lrate = d_model**(-0.5) * min(step**(-0.5), step * warmup_steps**(-1.5))\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return (self.d_model ** -0.5) * min(arg1, arg2)\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"스케줄러의 상태를 반환합니다.\"\"\"\n",
    "        return {'num_steps': self.num_steps}\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        \"\"\"스케줄러의 상태를 불러옵니다.\"\"\"\n",
    "        self.num_steps = state_dict['num_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델, 손실 함수 초기화 (Label Smoothing 포함)\n",
    "model = Transformer(N_LAYERS, D_MODEL, N_HEADS, D_FF, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, DROPOUT).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=ko_tokenizer.pad_id(), label_smoothing=0.1)\n",
    "\n",
    "# 옵티마이저: AdamW 사용 및 최대 학습률(peak_lr) 설정\n",
    "peak_lr = 5e-5\n",
    "optimizer = optim.AdamW(model.parameters(), lr=peak_lr, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.01)\n",
    "\n",
    "warmup_steps = 4000\n",
    "# 전체 훈련 스텝 계산 (CosineAnnealingLR의 T_max에 필요)\n",
    "total_training_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "# 1. Warmup 스케줄러 (LinearLR)\n",
    "# warmup_steps 동안 학습률을 0에서 peak_lr까지 선형적으로 증가\n",
    "warmup_scheduler = LinearLR(optimizer, start_factor=0.001, total_iters=warmup_steps)\n",
    "\n",
    "# 2. Main 스케줄러 (CosineAnnealingLR)\n",
    "# Warmup 이후, 남은 스텝 동안 학습률을 코사인 곡선을 따라 부드럽게 감소시킵니다.\n",
    "main_scheduler = CosineAnnealingLR(optimizer, T_max=total_training_steps - warmup_steps, eta_min=1e-6)\n",
    "\n",
    "# 3. 두 스케줄러를 순차적으로 연결 (SequentialLR)\n",
    "# warmup_steps 이전까지는 warmup_scheduler를, 이후에는 main_scheduler를 사용\n",
    "scheduler = SequentialLR(\n",
    "    optimizer,\n",
    "    schedulers=[warmup_scheduler, main_scheduler],\n",
    "    milestones=[warmup_steps]\n",
    ")\n",
    "\n",
    "print(\"훈련 설정이 'Warmup + Cosine Annealing' 스케줄러로 업그레이드되었습니다.\")\n",
    "print(f\"최대 학습률(Peak LR): {peak_lr}, 웜업 스텝: {warmup_steps}\")\n",
    "\n",
    "# 체크포인트 불러오기\n",
    "start_epoch = 0\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\"체크포인트를 불러옵니다: {CHECKPOINT_PATH}\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_valid_loss = checkpoint['best_valid_loss']\n",
    "    print(f\"체크포인트 로드 완료. Epoch {start_epoch + 1}부터 훈련을 재개합니다.\")\n",
    "    model.to(device) # 모델을 device로 이동\n",
    "else:\n",
    "    print(\"체크포인트가 없습니다. 처음부터 훈련을 시작합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, scheduler, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(iterator, desc=\"Training\", mininterval=0.5, leave=False)\n",
    "\n",
    "    for i, batch in enumerate(progress_bar):\n",
    "        src = batch[0].to(device)\n",
    "        tgt = batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output, _, _, _ = model(src, tgt[:,:-1])\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        tgt = tgt[:,1:].contiguous().view(-1)\n",
    "\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        scheduler.step()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item(), lr=scheduler.optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(iterator, desc=\"Evaluating\", mininterval=0.5, leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(progress_bar):\n",
    "            src = batch[0].to(device)\n",
    "            tgt = batch[1].to(device)\n",
    "\n",
    "            output, _, _, _ = model(src, tgt[:,:-1])\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            tgt = tgt[:,1:].contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(output, tgt)\n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# --- 학습 루프 ---\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02} / {EPOCHS:02}\")\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, scheduler, criterion, 1)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        early_stopping_counter = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_valid_loss': best_valid_loss,\n",
    "        }, CHECKPOINT_PATH)\n",
    "        print(f\"Validation loss improved. Checkpoint saved to {CHECKPOINT_PATH}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"Validation loss did not improve. Counter: {early_stopping_counter}/{EARLY_STOPPING_PATIENCE}\")\n",
    "\n",
    "    print(f'Time: {epoch_mins:.0f}m {epoch_secs:.0f}s')\n",
    "    print(f'\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    if early_stopping_counter >= EARLY_STOPPING_PATIENCE:\n",
    "        print(f\"조기 종료: {EARLY_STOPPING_PATIENCE} 에폭 동안 검증 손실이 개선되지 않았습니다.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 번역 (greedy Search, Beam Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 새로운 모델 객체를 만들고 저장된 가중치를 불러옴\n",
    "inference_model = Transformer(N_LAYERS, D_MODEL, N_HEADS, D_FF, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, DROPOUT).to(device)\n",
    "\n",
    "# 체크포인트는 딕셔너리 형태이므로, model_state_dict를 직접 로드해야 합니다.\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "inference_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# 2. 모델을 평가 모드로 설정\n",
    "inference_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_tokenizer, tgt_tokenizer, model, device, max_len=50):\n",
    "\n",
    "    src_tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "    src_tensor = torch.LongTensor(src_tokens).unsqueeze(0).to(device)\n",
    "\n",
    "    tgt_tokens = [tgt_tokenizer.bos_id()]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        tgt_tensor = torch.LongTensor(tgt_tokens).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, _, _, dec_enc_attns = model(src_tensor, tgt_tensor)\n",
    "\n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        tgt_tokens.append(pred_token)\n",
    "\n",
    "        if pred_token == tgt_tokenizer.eos_id():\n",
    "            break\n",
    "\n",
    "    tgt_sentence = tgt_tokenizer.decode_ids(tgt_tokens)\n",
    "    return tgt_sentence, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence_beam_search(sentence, src_tokenizer, tgt_tokenizer, model, device, max_len=50, beam_size=5):\n",
    "    \"\"\"\n",
    "    빔 서치(Beam Search)를 사용하여 문장을 번역하고, 최종 번역문에 대한 어텐션 맵을 반환하는 함수입니다.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    src_tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "    src_tensor = torch.LongTensor(src_tokens).unsqueeze(0).to(device)\n",
    "\n",
    "    beams = [(torch.LongTensor([tgt_tokenizer.bos_id()]).to(device), 0)]\n",
    "    completed_hypotheses = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        new_beams = []\n",
    "        for seq, score in beams:\n",
    "            if seq[-1].item() == tgt_tokenizer.eos_id():\n",
    "                completed_hypotheses.append((seq, score))\n",
    "                continue\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output, _, _, _ = model(src_tensor, seq.unsqueeze(0))\n",
    "\n",
    "            next_token_logits = output[:, -1, :]\n",
    "            next_token_log_probs = torch.log_softmax(next_token_logits, dim=-1)\n",
    "            top_next_tokens = torch.topk(next_token_log_probs, beam_size, dim=-1)\n",
    "\n",
    "            for i in range(beam_size):\n",
    "                token_id = top_next_tokens.indices[0][i].item()\n",
    "                log_prob = top_next_tokens.values[0][i].item()\n",
    "\n",
    "                new_seq = torch.cat([seq, torch.LongTensor([token_id]).to(device)])\n",
    "                new_score = score + log_prob\n",
    "                new_beams.append((new_seq, new_score))\n",
    "\n",
    "        if not new_beams:\n",
    "            break\n",
    "\n",
    "        beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_size]\n",
    "\n",
    "        if all(b[0][-1].item() == tgt_tokenizer.eos_id() for b in beams):\n",
    "            completed_hypotheses.extend(beams)\n",
    "            break\n",
    "\n",
    "    if not completed_hypotheses:\n",
    "        completed_hypotheses.extend(beams)\n",
    "\n",
    "    best_hypothesis = sorted(completed_hypotheses, key=lambda x: x[1] / len(x[0]), reverse=True)[0]\n",
    "    best_sequence = best_hypothesis[0]\n",
    "\n",
    "    translated_sentence = tgt_tokenizer.decode_ids(best_sequence.tolist())\n",
    "\n",
    "    # 최종 선택된 시퀀스에 대한 어텐션 맵을 얻기 위해 모델을 한 번 더 실행\n",
    "    with torch.no_grad():\n",
    "        # </s> 토큰은 어텐션 계산에 필요 없으므로, 있다면 제외\n",
    "        input_seq = best_sequence.unsqueeze(0)\n",
    "        if input_seq[0, -1].item() == tgt_tokenizer.eos_id():\n",
    "            input_seq = input_seq[:, :-1]\n",
    "\n",
    "        _, _, _, final_attentions = model(src_tensor, input_seq)\n",
    "\n",
    "    return translated_sentence, final_attentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역할 문장 선택\n",
    "example_idx = 1\n",
    "src = test_kor_corpus[example_idx]\n",
    "trg = test_eng_corpus[example_idx]\n",
    "\n",
    "# 빔 서치로 번역 실행 (beam_size=5)\n",
    "beam_translation, beam_attention = translate_sentence_beam_search(src, ko_tokenizer, en_tokenizer, inference_model, device, beam_size=5)\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')\n",
    "print(f'predicted trg (beam search) = {beam_translation}')\n",
    "\n",
    "# 기존 Greedy 방식과 비교\n",
    "greedy_translation, _ = translate_sentence(src, ko_tokenizer, en_tokenizer, inference_model, device)\n",
    "print(f'predicted trg (greedy)      = {greedy_translation}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 어텐션 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention, n_heads=8, n_rows=4, n_cols=2):\n",
    "    \"\"\"어텐션 맵을 시각화합니다.\"\"\"\n",
    "    assert n_rows * n_cols == n_heads\n",
    "\n",
    "    font_path = './NanumBarunGothic.ttf'\n",
    "    font_prop = fm.FontProperties(fname=font_path, size=8)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 28))  # x축을 조금 넓혀서 압축 줄임 (10->12)\n",
    "\n",
    "    # 번역된 문장과 원본 문장을 토큰 단위로 분리\n",
    "    sentence_tokens = sentence.split()\n",
    "    translation_tokens = translation.split()\n",
    "\n",
    "    for i in range(n_heads):\n",
    "        ax = fig.add_subplot(n_rows, n_cols, i + 1)\n",
    "\n",
    "        # attention shape: (head_idx, tgt_len, src_len)\n",
    "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
    "\n",
    "        # extent 명시: (-0.5, src_len-0.5, tgt_len-0.5, -0.5)로 ticks와 맞춤\n",
    "        src_len = len(sentence_tokens)\n",
    "        tgt_len = len(translation_tokens)\n",
    "        cax = ax.matshow(_attention, cmap='viridis', extent=[-0.5, src_len - 0.5, tgt_len - 0.5, -0.5])\n",
    "\n",
    "        # 눈금 위치 설정\n",
    "        ax.set_xticks(range(src_len))\n",
    "        ax.set_yticks(range(tgt_len))\n",
    "\n",
    "        # 라벨 설정: ha/va로 중앙 정렬\n",
    "        # 다른분꺼 보니까 45도가 좋아보이더만\n",
    "        ax.set_xticklabels(sentence_tokens, rotation=45, fontproperties=font_prop, ha='center', va='center')\n",
    "        ax.set_yticklabels(translation_tokens, fontproperties=font_prop, ha='right', va='center')\n",
    "\n",
    "        ax.tick_params(labelsize=8, pad=15)  # pad로 텍스트와 tick 간격 미세 조정\n",
    "\n",
    "    plt.tight_layout()  # subplot 간 여백 자동 조정 (밀림 방지)\n",
    "    plt.show()\n",
    "\n",
    "display_attention(src, beam_translation, beam_attention[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 최종 모델 성능 종합 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_scorer\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model_comprehensively(model, src_corpus, tgt_corpus, src_tokenizer, tgt_tokenizer, device, translate_function, beam_size=5):\n",
    "    \"\"\"\n",
    "    테스트 데이터셋 전체에 대해 번역을 수행하고,\n",
    "    BLEU, METEOR, ROUGE, BERTScore를 포함한\n",
    "    종합적인 평가지표를 계산하여 출력\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # 1. 전체 테스트 데이터셋에 대해 번역 생성\n",
    "    print(\"테스트 데이터셋 전체에 대한 번역을 시작합니다...\")\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for src_sentence, ref_sentence in tqdm(zip(src_corpus, tgt_corpus), total=len(src_corpus), desc=\"Translating\"):\n",
    "        pred_sentence, _ = translate_function(\n",
    "            src_sentence, src_tokenizer, tgt_tokenizer, model, device, beam_size=beam_size\n",
    "        )\n",
    "        predictions.append(pred_sentence)\n",
    "        references.append(ref_sentence)\n",
    "\n",
    "    print(\"번역 완료. 평가지표 계산을 시작합니다...\")\n",
    "\n",
    "    # 2. N-gram 기반 평가지표 계산 (BLEU, METEOR, ROUGE)\n",
    "    print(\"Calculating BLEU, METEOR, ROUGE scores...\")\n",
    "    pred_tokens = [p.split() for p in predictions]\n",
    "    ref_tokens = [[r.split()] for r in references]\n",
    "\n",
    "    # BLEU\n",
    "    smooth_fn = SmoothingFunction().method1\n",
    "    bleu_score = np.mean([sentence_bleu(r, p, smoothing_function=smooth_fn) for r, p in zip(ref_tokens, pred_tokens)])\n",
    "\n",
    "    # METEOR\n",
    "    meteor_score_avg = np.mean([meteor_score(r, p) for r, p in zip(ref_tokens, pred_tokens)])\n",
    "\n",
    "    # ROUGE\n",
    "    rouge_calculator = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    rouge1_f1, rougeL_f1 = [], []\n",
    "    for ref, pred in zip(references, predictions):\n",
    "        scores = rouge_calculator.score(ref, pred)\n",
    "        rouge1_f1.append(scores['rouge1'].fmeasure)\n",
    "        rougeL_f1.append(scores['rougeL'].fmeasure)\n",
    "    rouge1_avg = np.mean(rouge1_f1)\n",
    "    rougeL_avg = np.mean(rougeL_f1)\n",
    "\n",
    "    # 3. 의미 기반 평가지표 계산 (BERTScore)\n",
    "    print(\"Calculating BERTScore...\")\n",
    "    P, R, F1 = bert_scorer(predictions, references, lang=\"en\", device=device, verbose=True)\n",
    "    bert_f1_score = F1.mean().item()\n",
    "\n",
    "    # 4. 최종 결과 종합 출력\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"      종합 번역 성능 평가 결과      \")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"  BLEU Score   : {bleu_score * 100:.2f}\")\n",
    "    print(f\"  METEOR Score : {meteor_score_avg * 100:.2f}\")\n",
    "    print(f\"  ROUGE-1 (F1) : {rouge1_avg * 100:.2f}\")\n",
    "    print(f\"  ROUGE-L (F1) : {rougeL_avg * 100:.2f}\")\n",
    "    print(f\"  BERTScore (F1): {bert_f1_score * 100:.2f}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# 함수 호출하여 종합 평가 실행\n",
    "# 이전에 로드한 inference_model과 Mecab 처리된 test_kor_mecab을 사용\n",
    "evaluate_model_comprehensively(\n",
    "    inference_model,\n",
    "    test_kor_mecab,\n",
    "    test_eng_corpus,\n",
    "    ko_tokenizer,\n",
    "    en_tokenizer,\n",
    "    device,\n",
    "    translate_sentence_beam_search, # 빔 서치 함수 사용\n",
    "    beam_size=5\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goingdeeper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
