{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a288c237-fecc-4abb-a2fc-15b1c16e8ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================\n",
    "# 1. 라이브러리 설치 및 임포트\n",
    "# =========================================\n",
    "!pip install -q sentencepiece\n",
    "!pip install -q nltk\n",
    "\n",
    "# mecab 추가 설치 (필요 시 주석 해제해서 실행)\n",
    "'''\n",
    "!pip install konlpy\n",
    "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
    "%cd Mecab-ko-for-Google-Colab/\n",
    "!bash install_mecab-ko_on_colab_light_220429.sh\n",
    "%cd -\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import re\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# === [변경 지점] 추가: 데이터 증강용 WordNet 및 NLTK 리소스 ===\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c8b91d-5638-493c-a6b8-643885cc1888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 2. 하이퍼파라미터 및 설정\n",
    "# =========================================\n",
    "\n",
    "# Model Hyperparameters\n",
    "SRC_VOCAB_SIZE = 20000\n",
    "TGT_VOCAB_SIZE = 20000\n",
    "D_MODEL = 512\n",
    "N_LAYERS = 6\n",
    "N_HEADS = 8\n",
    "D_FF = 2048\n",
    "DROPOUT = 0.1\n",
    "MAX_LEN = 50\n",
    "\n",
    "# Training Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# === [변경 지점] 실험 고도화 옵션 ===\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "USE_AMP = True                 # 혼합정밀\n",
    "GRAD_ACCUM_STEPS = 2           # 그래디언트 누적\n",
    "MAX_GRAD_NORM = 1.0            # 그라디언트 클립\n",
    "LABEL_SMOOTHING = 0.1          # 라벨 스무딩\n",
    "WEIGHT_DECAY = 1e-4            # 가중치 감쇠\n",
    "WARMUP_STEPS = 4000            # Noam warmup steps\n",
    "PATIENCE = 3                   # 얼리스탑 인내심\n",
    "CHECKPOINT_DIR = \"./checkpoints\"\n",
    "BEST_MODEL_PATH = \"transformer-best.pt\"\n",
    "LAST_CKPT_PATH = os.path.join(CHECKPOINT_DIR, \"last.pt\")\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# === [핵심] 재개 여부 플래그: 기본 False → 항상 1에포크부터 시작 ===\n",
    "RESUME = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ccd9cfb-5167-427d-bdcc-4dfe73ec2d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 94123, Dev: 1000, Test: 2000\n",
      "After filter → Train: 77496, Dev: 984, Test: 1953\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 3. 데이터 준비 및 전처리\n",
    "# =========================================\n",
    "\n",
    "# 1) 데이터 경로\n",
    "data_dir = 'data'\n",
    "train_kor_path = os.path.join(data_dir, 'korean-english-park.train.ko')\n",
    "train_eng_path = os.path.join(data_dir, 'korean-english-park.train.en')\n",
    "dev_kor_path   = os.path.join(data_dir, 'korean-english-park.dev.ko')\n",
    "dev_eng_path   = os.path.join(data_dir, 'korean-english-park.dev.en')\n",
    "test_kor_path  = os.path.join(data_dir, 'korean-english-park.test.ko')\n",
    "test_eng_path  = os.path.join(data_dir, 'korean-english-park.test.en')\n",
    "\n",
    "# 2) 원본 데이터 로딩\n",
    "with open(train_kor_path, \"r\", encoding='utf-8') as f: train_kor_raw = f.read().splitlines()\n",
    "with open(train_eng_path, \"r\", encoding='utf-8') as f: train_eng_raw = f.read().splitlines()\n",
    "with open(dev_kor_path,   \"r\", encoding='utf-8') as f: dev_kor_raw   = f.read().splitlines()\n",
    "with open(dev_eng_path,   \"r\", encoding='utf-8') as f: dev_eng_raw   = f.read().splitlines()\n",
    "with open(test_kor_path,  \"r\", encoding='utf-8') as f: test_kor_raw  = f.read().splitlines()\n",
    "with open(test_eng_path,  \"r\", encoding='utf-8') as f: test_eng_raw  = f.read().splitlines()\n",
    "\n",
    "print(f\"Train: {len(train_kor_raw)}, Dev: {len(dev_kor_raw)}, Test: {len(test_kor_raw)}\")\n",
    "\n",
    "# 3) 전처리\n",
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"구두점, 특수문자 등 불필요한 부분을 제거하고 소문자로 변환합니다.\"\"\"\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z가-힣?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "def clean_and_preprocess_corpus(kor_raw, eng_raw):\n",
    "    \"\"\"문장 쌍 중복 제거 + 전처리\"\"\"\n",
    "    cleaned_pairs = list(set(zip(kor_raw, eng_raw)))\n",
    "    kor_corpus, eng_corpus = [], []\n",
    "    for kor, eng in cleaned_pairs:\n",
    "        kor_corpus.append(preprocess_sentence(kor))\n",
    "        eng_corpus.append(preprocess_sentence(eng))\n",
    "    return kor_corpus, eng_corpus\n",
    "\n",
    "# === [변경 지점] 추가: 길이 필터(과도한 메모리/노이즈 방지) ===\n",
    "def filter_by_length(srcs, tgts, max_len=MAX_LEN):\n",
    "    f_src, f_tgt = [], []\n",
    "    for s, t in zip(srcs, tgts):\n",
    "        if len(s.split()) <= max_len and len(t.split()) <= max_len:\n",
    "            f_src.append(s); f_tgt.append(t)\n",
    "    return f_src, f_tgt\n",
    "\n",
    "# 각 데이터셋에 대해 전처리\n",
    "train_kor_corpus, train_eng_corpus = clean_and_preprocess_corpus(train_kor_raw, train_eng_raw)\n",
    "dev_kor_corpus,   dev_eng_corpus   = clean_and_preprocess_corpus(dev_kor_raw,   dev_eng_raw)\n",
    "test_kor_corpus,  test_eng_corpus  = clean_and_preprocess_corpus(test_kor_raw,  test_eng_raw)\n",
    "\n",
    "# === [변경 지점] 길이 필터 적용 ===\n",
    "train_kor_corpus, train_eng_corpus = filter_by_length(train_kor_corpus, train_eng_corpus, MAX_LEN)\n",
    "dev_kor_corpus,   dev_eng_corpus   = filter_by_length(dev_kor_corpus,   dev_eng_corpus,   MAX_LEN)\n",
    "test_kor_corpus,  test_eng_corpus  = filter_by_length(test_kor_corpus,  test_eng_corpus,  MAX_LEN)\n",
    "\n",
    "print(f\"After filter → Train: {len(train_kor_corpus)}, Dev: {len(dev_kor_corpus)}, Test: {len(test_kor_corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b369530-4eb7-4b30-96bc-9e56d4428245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 이 자금은 대부분 이라크 주둔 군대 조직운영에 투자될 예정이며 아프간 파병군도 이 기금의 일부를 얻게 될 것이다 .\n",
      "After : 이 자금 은 대부분 이라크 주둔 군대 조직 운영 에 투자 될 예정 이 며 아프간 파병 군 도 이 기금 의 일부 를 얻 게 될 것 이 다 .\n"
     ]
    }
   ],
   "source": [
    "#=========================================================\n",
    "#================추가된 Mecab 단계(+안전 폴백)=============\n",
    "#=========================================================\n",
    "try:\n",
    "    from konlpy.tag import Mecab\n",
    "    mecab = Mecab()\n",
    "    def mecab_tokenize_corpus(corpus):\n",
    "        mecab_corpus = []\n",
    "        for sentence in corpus:\n",
    "            morphs = mecab.morphs(sentence)\n",
    "            mecab_corpus.append(\" \".join(morphs))\n",
    "        return mecab_corpus\n",
    "except Exception as e:\n",
    "    print(\"[경고] Mecab 사용 불가:\", e, \"\\n[대체] KoNLPy Okt로 폴백합니다(제출 시 Mecab 권장).\")\n",
    "    from konlpy.tag import Okt\n",
    "    _okt = Okt()\n",
    "    def mecab_tokenize_corpus(corpus):\n",
    "        return [\" \".join(_okt.morphs(sentence)) for sentence in corpus]\n",
    "\n",
    "# 한국어 데이터셋 Mecab/Okt 처리\n",
    "train_kor_mecab = mecab_tokenize_corpus(train_kor_corpus)\n",
    "dev_kor_mecab   = mecab_tokenize_corpus(dev_kor_corpus)\n",
    "test_kor_mecab  = mecab_tokenize_corpus(test_kor_corpus)\n",
    "\n",
    "print(\"Before:\", train_kor_corpus[0])\n",
    "print(\"After :\", train_kor_mecab[0])\n",
    "#=========================================================\n",
    "#========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a642a4f5-50ee-47da-b118-355ee8cc31a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=./ko_corpus.txt --model_prefix=ko_spm --vocab_size=20000 --pad_id=0 --bos_id=1 --eos_id=2 --unk_id=3\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./ko_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: ko_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: ./ko_corpus.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 77495 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=5823243\n",
      "trainer_interface.cc(552) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=1156\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 77495 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=2167116\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 36893 seed sentencepieces\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 77495\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 49715\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 49715 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=25952 obj=8.76964 num_tokens=96407 num_tokens/piece=3.71482\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=20567 obj=8.25086 num_tokens=96888 num_tokens/piece=4.71085\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: ko_spm.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: ko_spm.vocab\n",
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=./en_corpus.txt --model_prefix=en_spm --vocab_size=20000 --pad_id=0 --bos_id=1 --eos_id=2 --unk_id=3\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./en_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: en_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: ./en_corpus.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 77484 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=10214012\n",
      "trainer_interface.cc(552) LOG(INFO) Done: 99.9907% characters are covered.\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=29\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999907\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 77484 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=5366045\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 81834 seed sentencepieces\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 77484\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 43899\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 43899 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=34048 obj=9.87439 num_tokens=82071 num_tokens/piece=2.41045\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=25523 obj=8.01989 num_tokens=82538 num_tokens/piece=3.23387\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=21975 obj=7.93611 num_tokens=83086 num_tokens/piece=3.78093\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=21778 obj=7.91863 num_tokens=83491 num_tokens/piece=3.83373\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: en_spm.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: en_spm.vocab\n"
     ]
    }
   ],
   "source": [
    "def generate_tokenizer(corpus, vocab_size, lang, pad_id=0, bos_id=1, eos_id=2, unk_id=3):\n",
    "    file = f'./{lang}_corpus.txt'\n",
    "    model_prefix = f'{lang}_spm'\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        for row in corpus:\n",
    "            f.write(str(row) + '\\n')\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f'--input={file} --model_prefix={model_prefix} --vocab_size={vocab_size}'\n",
    "        f' --pad_id={pad_id} --bos_id={bos_id} --eos_id={eos_id} --unk_id={unk_id}'\n",
    "    )\n",
    "    tokenizer = spm.SentencePieceProcessor()\n",
    "    tokenizer.Load(f'{model_prefix}.model')\n",
    "    return tokenizer\n",
    "\n",
    "# 한국어는 mecab(또는 폴백)의 토큰화 결과, 영어는 원문 코퍼스 기준\n",
    "ko_tokenizer = generate_tokenizer(train_kor_mecab, SRC_VOCAB_SIZE, \"ko\")\n",
    "en_tokenizer = generate_tokenizer(train_eng_corpus, TGT_VOCAB_SIZE, \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea823e20-b98d-45ff-a9ce-063c69632156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Augment] +37622 → Total Train: 115118\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 4. 데이터 증강 (Lexical Substitution)\n",
    "# =========================================\n",
    "\n",
    "def synonym_replace_en(sentence, p=0.2):\n",
    "    tokens = sentence.split()\n",
    "    new_tokens = tokens[:]\n",
    "    for i, w in enumerate(tokens):\n",
    "        if random.random() < p and w.isalpha() and len(w) > 2:\n",
    "            syns = wn.synsets(w, lang='eng')\n",
    "            lemmas = set()\n",
    "            for s in syns:\n",
    "                for l in s.lemmas():\n",
    "                    lemma = l.name().replace('_', ' ').lower()\n",
    "                    if lemma.isalpha() and lemma != w:\n",
    "                        lemmas.add(lemma)\n",
    "            if lemmas:\n",
    "                new_tokens[i] = random.choice(list(lemmas))\n",
    "    return ' '.join(new_tokens)\n",
    "\n",
    "def random_swap(sentence, n_swaps=1):\n",
    "    tokens = sentence.split()\n",
    "    if len(tokens) < 2: return sentence\n",
    "    for _ in range(n_swaps):\n",
    "        i, j = random.sample(range(len(tokens)), 2)\n",
    "        tokens[i], tokens[j] = tokens[j], tokens[i]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def random_deletion(sentence, p=0.1):\n",
    "    tokens = sentence.split()\n",
    "    if len(tokens) <= 1: return sentence\n",
    "    kept = [t for t in tokens if random.random() > p]\n",
    "    if not kept: kept = [random.choice(tokens)]\n",
    "    return ' '.join(kept)\n",
    "\n",
    "def augment_pair(kor, eng):\n",
    "    # 한국어: 스왑/삭제 위주\n",
    "    kor_aug = kor\n",
    "    if random.random() < 0.5: kor_aug = random_swap(kor_aug, n_swaps=1)\n",
    "    if random.random() < 0.5: kor_aug = random_deletion(kor_aug, p=0.1)\n",
    "\n",
    "    # 영어: 동의어 치환 + 스왑/삭제\n",
    "    eng_aug = eng\n",
    "    if random.random() < 0.7: eng_aug = synonym_replace_en(eng_aug, p=0.2)\n",
    "    if random.random() < 0.3: eng_aug = random_swap(eng_aug, n_swaps=1)\n",
    "    if random.random() < 0.3: eng_aug = random_deletion(eng_aug, p=0.1)\n",
    "    return kor_aug, eng_aug\n",
    "\n",
    "def build_augmented_corpus(kor_mecab, eng_corpus, ratio=0.5, seed=SEED):\n",
    "    random.seed(seed)\n",
    "    n = len(kor_mecab)\n",
    "    k = int(n * ratio)  # 0.5배 → 전체 1.5배\n",
    "    indices = random.sample(range(n), k)\n",
    "    aug_ko, aug_en = [], []\n",
    "    for idx in indices:\n",
    "        k_aug, e_aug = augment_pair(kor_mecab[idx], eng_corpus[idx])\n",
    "        if len(k_aug.split()) <= MAX_LEN and len(e_aug.split()) <= MAX_LEN:\n",
    "            aug_ko.append(k_aug)\n",
    "            aug_en.append(e_aug)\n",
    "    return aug_ko, aug_en\n",
    "\n",
    "# 실제 증강 적용\n",
    "aug_ko, aug_en = build_augmented_corpus(train_kor_mecab, train_eng_corpus, ratio=0.5, seed=SEED)\n",
    "train_kor_mecab = train_kor_mecab + aug_ko\n",
    "train_eng_corpus = train_eng_corpus + aug_en\n",
    "\n",
    "# 셔플(동일 시드)\n",
    "tmp = list(zip(train_kor_mecab, train_eng_corpus))\n",
    "random.shuffle(tmp)\n",
    "train_kor_mecab, train_eng_corpus = zip(*tmp)\n",
    "train_kor_mecab, train_eng_corpus = list(train_kor_mecab), list(train_eng_corpus)\n",
    "print(f\"[Augment] +{len(aug_ko)} → Total Train: {len(train_kor_mecab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3378263c-6ad1-42fd-b42a-5598e04b8815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in train_loader: 1799\n",
      "Number of batches in valid_loader: 16\n",
      "Number of batches in test_loader: 31\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 5. 데이터셋 및 DataLoader 구축\n",
    "# =========================================\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_corpus, tgt_corpus, src_tokenizer, tgt_tokenizer):\n",
    "        self.src_corpus = src_corpus\n",
    "        self.tgt_corpus = tgt_corpus\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_corpus)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.src_tokenizer.encode_as_ids(self.src_corpus[idx])\n",
    "        tgt = self.tgt_tokenizer.encode_as_ids(self.tgt_corpus[idx])\n",
    "        return torch.tensor(src, dtype=torch.long), torch.tensor(tgt, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(src_sample)\n",
    "        tgt_batch.append(tgt_sample)\n",
    "    src_padded = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=ko_tokenizer.pad_id())\n",
    "    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=en_tokenizer.pad_id())\n",
    "    return src_padded, tgt_padded\n",
    "\n",
    "train_dataset = TranslationDataset(train_kor_mecab, train_eng_corpus, ko_tokenizer, en_tokenizer)\n",
    "valid_dataset = TranslationDataset(dev_kor_mecab,   dev_eng_corpus,   ko_tokenizer, en_tokenizer)\n",
    "test_dataset  = TranslationDataset(test_kor_mecab,  test_eng_corpus,  ko_tokenizer, en_tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  collate_fn=collate_fn, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=4)\n",
    "\n",
    "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
    "print(f\"Number of batches in valid_loader: {len(valid_loader)}\")\n",
    "print(f\"Number of batches in test_loader: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e7bdf2-3eed-4e3e-a355-8ba913f98a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 6. 트랜스포머 모델 정의 (마스크/타이잉 개선)\n",
    "# =========================================\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        div_term = torch.exp(torch.arange(0, emb_size, 2) * (-math.log(10000.0) / emb_size))\n",
    "        position = torch.arange(maxlen).unsqueeze(1)\n",
    "        pos_embedding = torch.zeros(maxlen, emb_size)\n",
    "        pos_embedding[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_embedding[:, 1::2] = torch.cos(position * div_term)\n",
    "        pos_embedding = pos_embedding.unsqueeze(0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:, :token_embedding.size(1), :])\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.depth = d_model // num_heads\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        d_k = Q.size(-1)\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / math.sqrt(d_k)  # (B, H, Lq, Lk)\n",
    "        if mask is not None:\n",
    "            if mask.dim() == 3:\n",
    "                mask = mask.unsqueeze(1)\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "        attentions = torch.softmax(scores, dim=-1)\n",
    "        out = torch.matmul(attentions, V)\n",
    "        return out, attentions\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz, seq_len, _ = x.size()\n",
    "        x = x.view(bsz, seq_len, self.num_heads, self.depth)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz, _, seq_len, _ = x.size()\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        return x.view(bsz, seq_len, self.d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        WQ = self.split_heads(self.W_q(Q))\n",
    "        WK = self.split_heads(self.W_k(K))\n",
    "        WV = self.split_heads(self.W_v(V))\n",
    "        out, attention_weights = self.scaled_dot_product_attention(WQ, WK, WV, mask)\n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "        return out, attention_weights\n",
    "\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "        self.norm_1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.norm_2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "    def forward(self, x, mask):\n",
    "        residual = x\n",
    "        out, enc_attn = self.enc_self_attn(self.norm_1(x), self.norm_1(x), self.norm_1(x), mask)\n",
    "        out = self.do(out) + residual\n",
    "        residual = out\n",
    "        out = self.ffn(self.norm_2(out))\n",
    "        out = self.do(out) + residual\n",
    "        return out, enc_attn\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "        self.norm_1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.norm_2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.norm_3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        residual = x\n",
    "        out, dec_attn = self.dec_self_attn(self.norm_1(x), self.norm_1(x), self.norm_1(x), mask=padding_mask)\n",
    "        out = self.do(out) + residual\n",
    "        residual = out\n",
    "        out, dec_enc_attn = self.enc_dec_attn(self.norm_2(out), enc_out, enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out) + residual\n",
    "        residual = out\n",
    "        out = self.ffn(self.norm_3(out))\n",
    "        out = self.do(out) + residual\n",
    "        return out, dec_attn, dec_enc_attn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_layers, d_model, n_heads, d_ff, dropout, vocab_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, dropout)\n",
    "        self.enc_layers = nn.ModuleList([EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        out = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        out = self.pos_encoding(out)\n",
    "        enc_attns = []\n",
    "        for layer in self.enc_layers:\n",
    "            out, enc_attn = layer(out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        return out, enc_attns\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_layers, d_model, n_heads, d_ff, dropout, vocab_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, dropout)\n",
    "        self.dec_layers = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        out = self.pos_encoding(out)\n",
    "        dec_attns, dec_enc_attns = [], []\n",
    "        for layer in self.dec_layers:\n",
    "            out, dec_attn, dec_enc_attn = layer(out, enc_out, dec_enc_mask, padding_mask)\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "        return out, dec_attns, dec_enc_attns\n",
    "\n",
    "# === [변경 지점] 마스크 유틸리티 추가 ===\n",
    "def create_padding_mask(seq, pad_id):\n",
    "    return (seq == pad_id).unsqueeze(1).unsqueeze(2)  # (B,1,1,L)\n",
    "\n",
    "def create_look_ahead_mask(size, device):\n",
    "    return torch.triu(torch.ones(size, size, device=device, dtype=torch.bool), diagonal=1)  # (L,L)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, n_layers, d_model, n_heads, d_ff, src_vocab_size, tgt_vocab_size, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout, src_vocab_size)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout, tgt_vocab_size)\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        # === [변경 지점] Weight Tying (Decoder 임베딩과 출력층 공유) ===\n",
    "        self.fc.weight = self.decoder.embedding.weight\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask = create_padding_mask(src, ko_tokenizer.pad_id())           # (B,1,1,SrcL)\n",
    "        tgt_pad_mask = create_padding_mask(tgt, en_tokenizer.pad_id())       # (B,1,1,TgtL)\n",
    "        lookahead = create_look_ahead_mask(tgt.size(1), device).unsqueeze(0).unsqueeze(1)  # (1,1,TgtL,TgtL)\n",
    "        dec_self_mask = tgt_pad_mask | lookahead                             # (B,1,TgtL,TgtL)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(src, src_mask)\n",
    "        dec_out, dec_attns, dec_enc_attns = self.decoder(tgt, enc_out, src_mask, dec_self_mask)\n",
    "        logits = self.fc(dec_out)\n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0587aef6-3680-481e-9eff-838665948af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30503/2497521859.py:51: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 7. 학습 설정 (고도화)\n",
    "# =========================================\n",
    "\n",
    "model = Transformer(N_LAYERS, D_MODEL, N_HEADS, D_FF, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, DROPOUT).to(device)\n",
    "\n",
    "# === [변경 지점] Label Smoothing + ignore_index=영어 PAD ===\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, ignore_index=-100):\n",
    "        super().__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.ignore_index = ignore_index\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = self.log_softmax(pred)  # (N,C)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.full_like(pred, self.smoothing / (self.cls - 1))\n",
    "            ignore_mask = target.eq(self.ignore_index)\n",
    "            target_clamped = target.clone()\n",
    "            target_clamped[ignore_mask] = 0  # dummy\n",
    "            true_dist.scatter_(1, target_clamped.unsqueeze(1), self.confidence)\n",
    "            true_dist[ignore_mask] = 0\n",
    "        loss = torch.sum(-true_dist * pred, dim=1)\n",
    "        loss = loss.masked_select(~ignore_mask).mean()\n",
    "        return loss\n",
    "\n",
    "criterion = LabelSmoothingLoss(classes=TGT_VOCAB_SIZE, smoothing=LABEL_SMOOTHING, ignore_index=en_tokenizer.pad_id())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# === [변경 지점] Noam 스케줄러 ===\n",
    "class NoamScheduler:\n",
    "    def __init__(self, optimizer, d_model, warmup_steps=4000):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup = warmup_steps\n",
    "        self._step = 0\n",
    "        self.factor = d_model ** (-0.5)\n",
    "    def step(self):\n",
    "        self._step += 1\n",
    "        lr = self.factor * min(self._step ** (-0.5), self._step * (self.warmup ** -1.5))\n",
    "        for pg in self.optimizer.param_groups:\n",
    "            pg['lr'] = lr\n",
    "        return lr\n",
    "    @property\n",
    "    def step_num(self):\n",
    "        return self._step\n",
    "\n",
    "scheduler = NoamScheduler(optimizer, d_model=D_MODEL, warmup_steps=WARMUP_STEPS)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca61572-746d-4e92-a5cc-1e8b3fa345f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01 / 10\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30503/2415141792.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=USE_AMP):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Step 200/1799 | Batch Loss: 10486.0215 | LR: 0.000017\n",
      "  - Step 400/1799 | Batch Loss: 8091.2275 | LR: 0.000035\n",
      "  - Step 600/1799 | Batch Loss: 5964.3398 | LR: 0.000052\n",
      "  - Step 800/1799 | Batch Loss: 4917.2529 | LR: 0.000070\n",
      "  - Step 1000/1799 | Batch Loss: 4588.4536 | LR: 0.000087\n",
      "  - Step 1200/1799 | Batch Loss: 3863.1375 | LR: 0.000105\n",
      "  - Step 1400/1799 | Batch Loss: 3692.7334 | LR: 0.000122\n",
      "  - Step 1600/1799 | Batch Loss: 3712.6096 | LR: 0.000140\n",
      "Evaluating...\n",
      "best model saved.\n",
      "Time: 5m 30s\n",
      "\tTrain Loss: 5815.647 | Train PPL: 485165195.410\n",
      "\t Val. Loss: 2732.062 |  Val. PPL: 485165195.410\n",
      "------------------------------\n",
      "\n",
      "Epoch 02 / 10\n",
      "Training...\n",
      "  - Step 200/1799 | Batch Loss: 2934.5679 | LR: 0.000175\n",
      "  - Step 400/1799 | Batch Loss: 2938.9463 | LR: 0.000192\n",
      "  - Step 600/1799 | Batch Loss: 2775.8247 | LR: 0.000209\n",
      "  - Step 800/1799 | Batch Loss: 2679.3535 | LR: 0.000227\n",
      "  - Step 1000/1799 | Batch Loss: 2506.5425 | LR: 0.000244\n",
      "  - Step 1200/1799 | Batch Loss: 2623.6423 | LR: 0.000262\n",
      "  - Step 1400/1799 | Batch Loss: 2910.3594 | LR: 0.000279\n",
      "  - Step 1600/1799 | Batch Loss: 4095.3855 | LR: 0.000297\n",
      "Evaluating...\n",
      "  [EarlyStop] no improv for 1/3\n",
      "Time: 5m 22s\n",
      "\tTrain Loss: 3065.730 | Train PPL: 485165195.410\n",
      "\t Val. Loss: 5592.625 |  Val. PPL: 485165195.410\n",
      "------------------------------\n",
      "\n",
      "Epoch 03 / 10\n",
      "Training...\n",
      "  - Step 200/1799 | Batch Loss: 6620.9629 | LR: 0.000332\n",
      "  - Step 400/1799 | Batch Loss: 6522.5674 | LR: 0.000349\n",
      "  - Step 600/1799 | Batch Loss: 6175.6636 | LR: 0.000367\n",
      "  - Step 800/1799 | Batch Loss: 5783.4468 | LR: 0.000384\n",
      "  - Step 1000/1799 | Batch Loss: 5391.1797 | LR: 0.000401\n",
      "  - Step 1200/1799 | Batch Loss: 4991.6641 | LR: 0.000419\n",
      "  - Step 1400/1799 | Batch Loss: 4607.7852 | LR: 0.000436\n",
      "  - Step 1600/1799 | Batch Loss: 4252.7764 | LR: 0.000454\n",
      "Evaluating...\n",
      "  [EarlyStop] no improv for 2/3\n",
      "Time: 5m 15s\n",
      "\tTrain Loss: 5478.682 | Train PPL: 485165195.410\n",
      "\t Val. Loss: 3883.355 |  Val. PPL: 485165195.410\n",
      "------------------------------\n",
      "\n",
      "Epoch 04 / 10\n",
      "Training...\n",
      "  - Step 200/1799 | Batch Loss: 3542.4028 | LR: 0.000489\n",
      "  - Step 400/1799 | Batch Loss: 3204.6431 | LR: 0.000506\n",
      "  - Step 600/1799 | Batch Loss: 2908.9736 | LR: 0.000524\n",
      "  - Step 800/1799 | Batch Loss: 2601.1255 | LR: 0.000541\n",
      "  - Step 1000/1799 | Batch Loss: 2348.6460 | LR: 0.000558\n",
      "  - Step 1200/1799 | Batch Loss: 2077.1467 | LR: 0.000576\n",
      "  - Step 1400/1799 | Batch Loss: 1827.1389 | LR: 0.000593\n",
      "  - Step 1600/1799 | Batch Loss: 1620.5372 | LR: 0.000611\n",
      "Evaluating...\n",
      "best model saved.\n",
      "Time: 5m 21s\n",
      "\tTrain Loss: 2528.957 | Train PPL: 485165195.410\n",
      "\t Val. Loss: 1403.792 |  Val. PPL: 485165195.410\n",
      "------------------------------\n",
      "\n",
      "Epoch 05 / 10\n",
      "Training...\n",
      "  - Step 200/1799 | Batch Loss: 1224.6241 | LR: 0.000646\n",
      "  - Step 400/1799 | Batch Loss: 1057.2126 | LR: 0.000663\n",
      "  - Step 600/1799 | Batch Loss: 902.9097 | LR: 0.000681\n",
      "  - Step 800/1799 | Batch Loss: 764.4625 | LR: 0.000698\n",
      "  - Step 1000/1799 | Batch Loss: 644.9517 | LR: 0.000691\n",
      "  - Step 1200/1799 | Batch Loss: 549.8724 | LR: 0.000682\n",
      "  - Step 1400/1799 | Batch Loss: 464.8422 | LR: 0.000674\n",
      "  - Step 1600/1799 | Batch Loss: 390.6333 | LR: 0.000667\n",
      "Evaluating...\n",
      "best model saved.\n",
      "Time: 5m 19s\n",
      "\tTrain Loss: 760.121 | Train PPL: 485165195.410\n",
      "\t Val. Loss: 328.796 |  Val. PPL: 485165195.410\n",
      "------------------------------\n",
      "\n",
      "Epoch 06 / 10\n",
      "Training...\n",
      "  - Step 200/1799 | Batch Loss: 280.0543 | LR: 0.000652\n",
      "  - Step 400/1799 | Batch Loss: 236.5293 | LR: 0.000645\n",
      "  - Step 600/1799 | Batch Loss: 197.5233 | LR: 0.000638\n",
      "  - Step 800/1799 | Batch Loss: 160.8712 | LR: 0.000632\n",
      "  - Step 1000/1799 | Batch Loss: 137.2450 | LR: 0.000625\n",
      "  - Step 1200/1799 | Batch Loss: 113.6243 | LR: 0.000619\n",
      "  - Step 1400/1799 | Batch Loss: 94.3552 | LR: 0.000613\n",
      "  - Step 1600/1799 | Batch Loss: 80.6550 | LR: 0.000607\n",
      "Evaluating...\n",
      "best model saved.\n",
      "Time: 5m 18s\n",
      "\tTrain Loss: 166.233 | Train PPL: 485165195.410\n",
      "\t Val. Loss: 67.501 |  Val. PPL: 485165195.410\n",
      "------------------------------\n",
      "\n",
      "Epoch 07 / 10\n",
      "Training...\n",
      "  - Step 200/1799 | Batch Loss: 56.7924 | LR: 0.000596\n",
      "  - Step 400/1799 | Batch Loss: 50.3210 | LR: 0.000591\n",
      "  - Step 600/1799 | Batch Loss: 42.2693 | LR: 0.000586\n",
      "  - Step 800/1799 | Batch Loss: 36.1073 | LR: 0.000581\n",
      "  - Step 1000/1799 | Batch Loss: 30.3112 | LR: 0.000576\n",
      "  - Step 1200/1799 | Batch Loss: 27.5849 | LR: 0.000571\n",
      "  - Step 1400/1799 | Batch Loss: 23.7616 | LR: 0.000566\n",
      "  - Step 1600/1799 | Batch Loss: 20.4880 | LR: 0.000562\n",
      "Evaluating...\n",
      "best model saved.\n",
      "Time: 5m 18s\n",
      "\tTrain Loss: 36.656 | Train PPL: 485165195.410\n",
      "\t Val. Loss: 17.957 |  Val. PPL: 62904996.503\n",
      "------------------------------\n",
      "\n",
      "Epoch 08 / 10\n",
      "Training...\n",
      "  - Step 200/1799 | Batch Loss: 16.4924 | LR: 0.000553\n",
      "  - Step 400/1799 | Batch Loss: 14.8909 | LR: 0.000548\n",
      "  - Step 600/1799 | Batch Loss: 13.9833 | LR: 0.000544\n",
      "  - Step 800/1799 | Batch Loss: 13.0959 | LR: 0.000540\n",
      "  - Step 1000/1799 | Batch Loss: 12.3273 | LR: 0.000536\n",
      "  - Step 1200/1799 | Batch Loss: 11.6906 | LR: 0.000532\n",
      "  - Step 1400/1799 | Batch Loss: 11.0927 | LR: 0.000528\n",
      "  - Step 1600/1799 | Batch Loss: 10.6846 | LR: 0.000525\n",
      "Evaluating...\n",
      "  [EarlyStop] no improv for 1/3\n",
      "Time: 5m 13s\n",
      "\tTrain Loss: nan | Train PPL: 485165195.410\n",
      "\t Val. Loss: nan |  Val. PPL: 485165195.410\n",
      "------------------------------\n",
      "\n",
      "Epoch 09 / 10\n",
      "Training...\n",
      "  - Step 200/1799 | Batch Loss: nan | LR: 0.000518\n",
      "  - Step 400/1799 | Batch Loss: nan | LR: 0.000514\n",
      "  - Step 600/1799 | Batch Loss: nan | LR: 0.000511\n",
      "  - Step 800/1799 | Batch Loss: nan | LR: 0.000507\n",
      "  - Step 1000/1799 | Batch Loss: nan | LR: 0.000504\n",
      "  - Step 1200/1799 | Batch Loss: nan | LR: 0.000501\n",
      "  - Step 1400/1799 | Batch Loss: nan | LR: 0.000497\n",
      "  - Step 1600/1799 | Batch Loss: nan | LR: 0.000494\n",
      "Evaluating...\n",
      "  [EarlyStop] no improv for 2/3\n",
      "Time: 4m 47s\n",
      "\tTrain Loss: nan | Train PPL: 485165195.410\n",
      "\t Val. Loss: nan |  Val. PPL: 485165195.410\n",
      "------------------------------\n",
      "\n",
      "Epoch 10 / 10\n",
      "Training...\n",
      "  - Step 200/1799 | Batch Loss: nan | LR: 0.000488\n",
      "  - Step 400/1799 | Batch Loss: nan | LR: 0.000485\n",
      "  - Step 600/1799 | Batch Loss: nan | LR: 0.000482\n",
      "  - Step 800/1799 | Batch Loss: nan | LR: 0.000480\n",
      "  - Step 1000/1799 | Batch Loss: nan | LR: 0.000477\n",
      "  - Step 1200/1799 | Batch Loss: nan | LR: 0.000474\n",
      "  - Step 1400/1799 | Batch Loss: nan | LR: 0.000471\n",
      "  - Step 1600/1799 | Batch Loss: nan | LR: 0.000469\n",
      "Evaluating...\n",
      "  [EarlyStop] no improv for 3/3\n",
      "Time: 4m 48s\n",
      "\tTrain Loss: nan | Train PPL: 485165195.410\n",
      "\t Val. Loss: nan |  Val. PPL: 485165195.410\n",
      "------------------------------\n",
      "[EarlyStop] Stopping training early.\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 8. 학습 및 검증 (AMP/누적/체크포인트/얼리스탑)\n",
    "# =========================================\n",
    "\n",
    "# === 체크포인트 유틸 ===\n",
    "def save_checkpoint(path, model, optimizer, scheduler, scaler, epoch, best_valid):\n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler_step': scheduler.step_num,\n",
    "        'scaler': scaler.state_dict() if scaler is not None else None,\n",
    "        'epoch': epoch,                 # 현재 완료한 에포크 인덱스(0-based)\n",
    "        'best_valid': best_valid\n",
    "    }, path)\n",
    "\n",
    "def load_checkpoint(path, model, optimizer, scheduler, scaler):\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "    optimizer.load_state_dict(ckpt['optimizer'])\n",
    "    if 'scheduler_step' in ckpt and ckpt['scheduler_step'] is not None:\n",
    "        scheduler._step = ckpt['scheduler_step']\n",
    "    if scaler is not None and ckpt.get('scaler') is not None:\n",
    "        scaler.load_state_dict(ckpt['scaler'])\n",
    "    return ckpt.get('epoch', 0), ckpt.get('best_valid', float('inf'))\n",
    "\n",
    "# === 얼리스탑 ===\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=PATIENCE, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best = None\n",
    "        self.early_stop = False\n",
    "        self.verbose = verbose\n",
    "    def step(self, metric):\n",
    "        if self.best is None or metric < self.best - 1e-9:\n",
    "            self.best = metric\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"  [EarlyStop] no improv for {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, log_interval=100, scheduler=None, scaler=None):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    for step, batch in enumerate(iterator, start=1):\n",
    "        src = batch[0].to(device)\n",
    "        tgt = batch[1].to(device)\n",
    "        with torch.cuda.amp.autocast(enabled=USE_AMP):\n",
    "            output, _, _, _ = model(src, tgt[:, :-1])\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            tgt_flat = tgt[:, 1:].contiguous().view(-1)\n",
    "            loss = criterion(output, tgt_flat) / GRAD_ACCUM_STEPS\n",
    "\n",
    "        if scaler is not None and USE_AMP:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        if step % GRAD_ACCUM_STEPS == 0:\n",
    "            if MAX_GRAD_NORM is not None:\n",
    "                if scaler is not None and USE_AMP:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "\n",
    "            if scaler is not None and USE_AMP:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item() * GRAD_ACCUM_STEPS\n",
    "\n",
    "        if (step) % log_interval == 0:\n",
    "            curr_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"  - Step {step}/{len(iterator)} | Batch Loss: {loss.item()*GRAD_ACCUM_STEPS:.4f} | LR: {curr_lr:.6f}\")\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            src = batch[0].to(device)\n",
    "            tgt = batch[1].to(device)\n",
    "            output, _, _, _ = model(src, tgt[:, :-1])\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            tgt_flat = tgt[:, 1:].contiguous().view(-1)\n",
    "            loss = criterion(output, tgt_flat)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# --- 학습 루프 (체크포인트/얼리스탑/재개 안전) ---\n",
    "best_valid_loss = float('inf')\n",
    "early_stopper = EarlyStopping(patience=PATIENCE, verbose=True)\n",
    "\n",
    "START_EPOCH = 0\n",
    "if RESUME and os.path.exists(LAST_CKPT_PATH):\n",
    "    print(f\"[Resume] Loading last checkpoint from {LAST_CKPT_PATH}\")\n",
    "    last_epoch, best_valid_loss = load_checkpoint(LAST_CKPT_PATH, model, optimizer, scheduler, scaler)\n",
    "    START_EPOCH = last_epoch + 1  # ← 저장된 마지막 에포크의 '다음'부터 시작\n",
    "    print(f\"[Resume] Will start from epoch {START_EPOCH+1}/{EPOCHS} (best_valid={best_valid_loss:.4f})\")\n",
    "\n",
    "if START_EPOCH >= EPOCHS:\n",
    "    print(\"[Resume] Training already completed. Nothing to do.\")\n",
    "else:\n",
    "    for epoch in range(START_EPOCH, EPOCHS):\n",
    "        start_time = time.time()\n",
    "        print(f\"\\nEpoch {epoch+1:02} / {EPOCHS:02}\")\n",
    "        print(\"Training...\")\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, clip=1, log_interval=200, scheduler=scheduler, scaler=scaler)\n",
    "\n",
    "        print(\"Evaluating...\")\n",
    "        valid_loss = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "        # 체크포인트 저장(라스트)\n",
    "        save_checkpoint(LAST_CKPT_PATH, model, optimizer, scheduler, scaler, epoch, best_valid_loss)\n",
    "\n",
    "        # 베스트 저장\n",
    "        if valid_loss < best_valid_loss - 1e-9:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "            print(\"best model saved.\")\n",
    "\n",
    "        # 얼리스탑 판정\n",
    "        early_stopper.step(valid_loss)\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "\n",
    "        print(f'Time: {int(epoch_mins)}m {int(epoch_secs)}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(min(20, train_loss)) :7.3f}')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(min(20, valid_loss)):7.3f}')\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"[EarlyStop] Stopping training early.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca8b23b7-99ed-4861-a817-b35d6f4fa948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Loaded best model for inference.\n",
      "src = 토론에 참여한 사람들은 법 집행과 국가 안전보장에 대한 우려를 표명해야 할 필요성을 진지하게 받아 들이고 있습니다.\n",
      "trg = Those involved in the discussions do take seriously the need to address concerns of law enforcement and national security.\n",
      "predicted trg = nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis nis\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 9. 번역 및 성능 평가 (BLEU)\n",
    "# =========================================\n",
    "\n",
    "def translate_sentence(sentence, src_tokenizer, tgt_tokenizer, model, device, max_len=50):\n",
    "    model.eval()\n",
    "    src_tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "    src_tensor = torch.LongTensor(src_tokens).unsqueeze(0).to(device)\n",
    "    tgt_tokens = [tgt_tokenizer.bos_id()]\n",
    "    dec_enc_attns_all = None\n",
    "    for i in range(max_len):\n",
    "        tgt_tensor = torch.LongTensor(tgt_tokens).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, _, _, dec_enc_attns = model(src_tensor, tgt_tensor)\n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        tgt_tokens.append(pred_token)\n",
    "        dec_enc_attns_all = dec_enc_attns  # 마지막 스텝의 어텐션들\n",
    "        if pred_token == tgt_tokenizer.eos_id():\n",
    "            break\n",
    "    tgt_sentence = tgt_tokenizer.decode_ids(tgt_tokens)\n",
    "    return tgt_sentence, dec_enc_attns_all\n",
    "\n",
    "# (베스트 모델 로드하여 추론)\n",
    "if os.path.exists(BEST_MODEL_PATH):\n",
    "    model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device))\n",
    "    print(\"[Info] Loaded best model for inference.\")\n",
    "\n",
    "example_idx = 0\n",
    "src = test_kor_raw[example_idx]\n",
    "trg = test_eng_raw[example_idx]\n",
    "translation, attention = translate_sentence(src, ko_tokenizer, en_tokenizer, model, device)\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')\n",
    "print(f'predicted trg = {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cbdeba5-30a5-4b3e-afaf-84a76b2a4156",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m     plt.tight_layout()\n\u001b[32m     34\u001b[39m     plt.show()\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43mdisplay_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mdisplay_attention\u001b[39m\u001b[34m(sentence, translation, attention, n_heads, n_rows, n_cols)\u001b[39m\n\u001b[32m     30\u001b[39m     ax.set_yticklabels(translation_tokens, fontproperties=font_prop, ha=\u001b[33m'\u001b[39m\u001b[33mright\u001b[39m\u001b[33m'\u001b[39m, va=\u001b[33m'\u001b[39m\u001b[33mcenter\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     31\u001b[39m     ax.tick_params(labelsize=\u001b[32m8\u001b[39m, pad=\u001b[32m15\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtight_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m plt.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/pyplot.py:2844\u001b[39m, in \u001b[36mtight_layout\u001b[39m\u001b[34m(pad, h_pad, w_pad, rect)\u001b[39m\n\u001b[32m   2836\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure.tight_layout)\n\u001b[32m   2837\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtight_layout\u001b[39m(\n\u001b[32m   2838\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2842\u001b[39m     rect: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2843\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2844\u001b[39m     \u001b[43mgcf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtight_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_pad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mh_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_pad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrect\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/figure.py:3640\u001b[39m, in \u001b[36mFigure.tight_layout\u001b[39m\u001b[34m(self, pad, h_pad, w_pad, rect)\u001b[39m\n\u001b[32m   3638\u001b[39m previous_engine = \u001b[38;5;28mself\u001b[39m.get_layout_engine()\n\u001b[32m   3639\u001b[39m \u001b[38;5;28mself\u001b[39m.set_layout_engine(engine)\n\u001b[32m-> \u001b[39m\u001b[32m3640\u001b[39m \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3641\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m previous_engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   3642\u001b[39m     previous_engine, (TightLayoutEngine, PlaceHolderLayoutEngine)\n\u001b[32m   3643\u001b[39m ):\n\u001b[32m   3644\u001b[39m     _api.warn_external(\u001b[33m'\u001b[39m\u001b[33mThe figure layout has changed to tight\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/layout_engine.py:188\u001b[39m, in \u001b[36mTightLayoutEngine.execute\u001b[39m\u001b[34m(self, fig)\u001b[39m\n\u001b[32m    186\u001b[39m renderer = fig._get_renderer()\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[33m\"\u001b[39m\u001b[33m_draw_disabled\u001b[39m\u001b[33m\"\u001b[39m, nullcontext)():\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     kwargs = \u001b[43mget_tight_layout_figure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_subplotspec_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpad\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_pad\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mh_pad\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_pad\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mw_pad\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrect\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[32m    193\u001b[39m     fig.subplots_adjust(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/_tight_layout.py:266\u001b[39m, in \u001b[36mget_tight_layout_figure\u001b[39m\u001b[34m(fig, axes_list, subplotspec_list, renderer, pad, h_pad, w_pad, rect)\u001b[39m\n\u001b[32m    261\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[32m    262\u001b[39m     span_pairs.append((\n\u001b[32m    263\u001b[39m         \u001b[38;5;28mslice\u001b[39m(ss.rowspan.start * div_row, ss.rowspan.stop * div_row),\n\u001b[32m    264\u001b[39m         \u001b[38;5;28mslice\u001b[39m(ss.colspan.start * div_col, ss.colspan.stop * div_col)))\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m kwargs = \u001b[43m_auto_adjust_subplotpars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_nrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ncols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mspan_pairs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspan_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43msubplot_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubplot_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43max_bbox_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43max_bbox_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_pad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mh_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_pad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw_pad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;66;03m# kwargs can be none if tight_layout fails...\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m     \u001b[38;5;66;03m# if rect is given, the whole subplots area (including\u001b[39;00m\n\u001b[32m    276\u001b[39m     \u001b[38;5;66;03m# labels) will fit into the rect instead of the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    280\u001b[39m     \u001b[38;5;66;03m# auto_adjust_subplotpars twice, where the second run\u001b[39;00m\n\u001b[32m    281\u001b[39m     \u001b[38;5;66;03m# with adjusted rect parameters.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/_tight_layout.py:82\u001b[39m, in \u001b[36m_auto_adjust_subplotpars\u001b[39m\u001b[34m(fig, renderer, shape, span_pairs, subplot_list, ax_bbox_list, pad, h_pad, w_pad, rect)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m subplots:\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ax.get_visible():\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         bb += [\u001b[43mmartist\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_tightbbox_for_layout_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m     84\u001b[39m tight_bbox_raw = Bbox.union(bb)\n\u001b[32m     85\u001b[39m tight_bbox = fig.transFigure.inverted().transform_bbox(tight_bbox_raw)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/artist.py:1402\u001b[39m, in \u001b[36m_get_tightbbox_for_layout_only\u001b[39m\u001b[34m(obj, *args, **kwargs)\u001b[39m\n\u001b[32m   1396\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1397\u001b[39m \u001b[33;03mMatplotlib's `.Axes.get_tightbbox` and `.Axis.get_tightbbox` support a\u001b[39;00m\n\u001b[32m   1398\u001b[39m \u001b[33;03m*for_layout_only* kwarg; this helper tries to use the kwarg but skips it\u001b[39;00m\n\u001b[32m   1399\u001b[39m \u001b[33;03mwhen encountering third-party subclasses that do not support it.\u001b[39;00m\n\u001b[32m   1400\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1401\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfor_layout_only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1404\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.get_tightbbox(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/axes/_base.py:4554\u001b[39m, in \u001b[36m_AxesBase.get_tightbbox\u001b[39m\u001b[34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[39m\n\u001b[32m   4552\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._axis_map.values():\n\u001b[32m   4553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axison \u001b[38;5;129;01mand\u001b[39;00m axis.get_visible():\n\u001b[32m-> \u001b[39m\u001b[32m4554\u001b[39m         ba = \u001b[43mmartist\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_tightbbox_for_layout_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4555\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m ba:\n\u001b[32m   4556\u001b[39m             bb.append(ba)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/artist.py:1402\u001b[39m, in \u001b[36m_get_tightbbox_for_layout_only\u001b[39m\u001b[34m(obj, *args, **kwargs)\u001b[39m\n\u001b[32m   1396\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1397\u001b[39m \u001b[33;03mMatplotlib's `.Axes.get_tightbbox` and `.Axis.get_tightbbox` support a\u001b[39;00m\n\u001b[32m   1398\u001b[39m \u001b[33;03m*for_layout_only* kwarg; this helper tries to use the kwarg but skips it\u001b[39;00m\n\u001b[32m   1399\u001b[39m \u001b[33;03mwhen encountering third-party subclasses that do not support it.\u001b[39;00m\n\u001b[32m   1400\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1401\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfor_layout_only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1404\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.get_tightbbox(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/axis.py:1353\u001b[39m, in \u001b[36mAxis.get_tightbbox\u001b[39m\u001b[34m(self, renderer, for_layout_only)\u001b[39m\n\u001b[32m   1350\u001b[39m     renderer = \u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m)._get_renderer()\n\u001b[32m   1351\u001b[39m ticks_to_draw = \u001b[38;5;28mself\u001b[39m._update_ticks()\n\u001b[32m-> \u001b[39m\u001b[32m1353\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_label_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[38;5;66;03m# go back to just this axis's tick labels\u001b[39;00m\n\u001b[32m   1356\u001b[39m tlb1, tlb2 = \u001b[38;5;28mself\u001b[39m._get_ticklabel_bboxes(ticks_to_draw, renderer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/axis.py:2448\u001b[39m, in \u001b[36mXAxis._update_label_position\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   2444\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2446\u001b[39m \u001b[38;5;66;03m# get bounding boxes for this axis and any siblings\u001b[39;00m\n\u001b[32m   2447\u001b[39m \u001b[38;5;66;03m# that have been set by `fig.align_xlabels()`\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2448\u001b[39m bboxes, bboxes2 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_tick_boxes_siblings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2449\u001b[39m x, y = \u001b[38;5;28mself\u001b[39m.label.get_position()\n\u001b[32m   2451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.label_position == \u001b[33m'\u001b[39m\u001b[33mbottom\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   2452\u001b[39m     \u001b[38;5;66;03m# Union with extents of the bottom spine if present, of the axes otherwise.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/axis.py:2241\u001b[39m, in \u001b[36mAxis._get_tick_boxes_siblings\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   2239\u001b[39m axis = ax._axis_map[name]\n\u001b[32m   2240\u001b[39m ticks_to_draw = axis._update_ticks()\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m tlb, tlb2 = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_ticklabel_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticks_to_draw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2242\u001b[39m bboxes.extend(tlb)\n\u001b[32m   2243\u001b[39m bboxes2.extend(tlb2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/axis.py:1334\u001b[39m, in \u001b[36mAxis._get_ticklabel_bboxes\u001b[39m\u001b[34m(self, ticks, renderer)\u001b[39m\n\u001b[32m   1330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1331\u001b[39m     renderer = \u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m)._get_renderer()\n\u001b[32m   1332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick.label1.get_window_extent(renderer)\n\u001b[32m   1333\u001b[39m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick.label1.get_visible()],\n\u001b[32m-> \u001b[39m\u001b[32m1334\u001b[39m         [\u001b[43mtick\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlabel2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1335\u001b[39m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick.label2.get_visible()])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/text.py:969\u001b[39m, in \u001b[36mText.get_window_extent\u001b[39m\u001b[34m(self, renderer, dpi)\u001b[39m\n\u001b[32m    964\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    966\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwant to call \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfigure.draw_without_rendering()\u001b[39m\u001b[33m'\u001b[39m\u001b[33m first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m cbook._setattr_cm(fig, dpi=dpi):\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     bbox, info, descent = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_renderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     x, y = \u001b[38;5;28mself\u001b[39m.get_unitless_position()\n\u001b[32m    971\u001b[39m     x, y = \u001b[38;5;28mself\u001b[39m.get_transform().transform((x, y))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/text.py:373\u001b[39m, in \u001b[36mText._get_layout\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m    370\u001b[39m ys = []\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# Full vertical extent of font, including ascenders and descenders:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m _, lp_h, lp_d = \u001b[43m_get_text_metrics_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fontproperties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTeX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_usetex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m min_dy = (lp_h - lp_d) * \u001b[38;5;28mself\u001b[39m._linespacing\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lines):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/text.py:69\u001b[39m, in \u001b[36m_get_text_metrics_with_cache\u001b[39m\u001b[34m(renderer, text, fontprop, ismath, dpi)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Cached based on a copy of fontprop so that later in-place mutations of\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# the passed-in argument do not mess up the cache.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_text_metrics_with_cache_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/text.py:77\u001b[39m, in \u001b[36m_get_text_metrics_with_cache_impl\u001b[39m\u001b[34m(renderer_ref, text, fontprop, ismath, dpi)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache(\u001b[32m4096\u001b[39m)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_text_metrics_with_cache_impl\u001b[39m(\n\u001b[32m     75\u001b[39m         renderer_ref, text, fontprop, ismath, dpi):\n\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# dpi is unused, but participates in cache invalidation (via the renderer).\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrenderer_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_text_width_height_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:218\u001b[39m, in \u001b[36mRendererAgg.get_text_width_height_descent\u001b[39m\u001b[34m(self, s, prop, ismath)\u001b[39m\n\u001b[32m    214\u001b[39m     ox, oy, width, height, descent, font_image = \\\n\u001b[32m    215\u001b[39m         \u001b[38;5;28mself\u001b[39m.mathtext_parser.parse(s, \u001b[38;5;28mself\u001b[39m.dpi, prop)\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m width, height, descent\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m font = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_font\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m font.set_text(s, \u001b[32m0.0\u001b[39m, flags=get_hinting_flag())\n\u001b[32m    220\u001b[39m w, h = font.get_width_height()  \u001b[38;5;66;03m# width and height of unrotated string\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:252\u001b[39m, in \u001b[36mRendererAgg._prepare_font\u001b[39m\u001b[34m(self, font_prop)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prepare_font\u001b[39m(\u001b[38;5;28mself\u001b[39m, font_prop):\n\u001b[32m    249\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[33;03m    Get the `.FT2Font` for *font_prop*, clear its buffer, and set its size.\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     font = \u001b[43mget_font\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fontManager\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_find_fonts_by_props\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont_prop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m     font.clear()\n\u001b[32m    254\u001b[39m     size = font_prop.get_size_in_points()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/font_manager.py:1615\u001b[39m, in \u001b[36mget_font\u001b[39m\u001b[34m(font_filepaths, hinting_factor)\u001b[39m\n\u001b[32m   1612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hinting_factor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1613\u001b[39m     hinting_factor = mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33mtext.hinting_factor\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m1615\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# must be a tuple to be cached\u001b[39;49;00m\n\u001b[32m   1617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrcParams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext.kerning_factor\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# also key on the thread ID to prevent segfaults with multi-threading\u001b[39;49;00m\n\u001b[32m   1621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreading\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_ident\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/font_manager.py:1557\u001b[39m, in \u001b[36m_get_font\u001b[39m\u001b[34m(font_filepaths, hinting_factor, _kerning_factor, thread_id)\u001b[39m\n\u001b[32m   1554\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m(\u001b[32m64\u001b[39m)\n\u001b[32m   1555\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_font\u001b[39m(font_filepaths, hinting_factor, *, _kerning_factor, thread_id):\n\u001b[32m   1556\u001b[39m     first_fontpath, *rest = font_filepaths\n\u001b[32m-> \u001b[39m\u001b[32m1557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mft2font\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFT2Font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfirst_fontpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_fallback_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[43m            \u001b[49m\u001b[43mft2font\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFT2Font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_kerning_factor\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrest\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_kerning_factor\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _draw_all_if_interactive at 0x787ce8202520> (for post_execute), with arguments args (),kwargs {}:\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/pyplot.py:279\u001b[39m, in \u001b[36m_draw_all_if_interactive\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_draw_all_if_interactive\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m matplotlib.is_interactive():\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m         \u001b[43mdraw_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/_pylab_helpers.py:131\u001b[39m, in \u001b[36mGcf.draw_all\u001b[39m\u001b[34m(cls, force)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m manager \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.get_all_fig_managers():\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m force \u001b[38;5;129;01mor\u001b[39;00m manager.canvas.figure.stale:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m         \u001b[43mmanager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/backend_bases.py:1891\u001b[39m, in \u001b[36mFigureCanvasBase.draw_idle\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1889\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_idle_drawing:\n\u001b[32m   1890\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._idle_draw_cntx():\n\u001b[32m-> \u001b[39m\u001b[32m1891\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:382\u001b[39m, in \u001b[36mFigureCanvasAgg.draw\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.toolbar._wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.toolbar\n\u001b[32m    381\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[32m    384\u001b[39m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[32m    385\u001b[39m     \u001b[38;5;28msuper\u001b[39m().draw()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/artist.py:94\u001b[39m, in \u001b[36m_finalize_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdraw_wrapper\u001b[39m(artist, renderer, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     result = \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m renderer._rasterizing:\n\u001b[32m     96\u001b[39m         renderer.stop_rasterizing()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/figure.py:3257\u001b[39m, in \u001b[36mFigure.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3254\u001b[39m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[32m   3256\u001b[39m     \u001b[38;5;28mself\u001b[39m.patch.draw(renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3257\u001b[39m     \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3260\u001b[39m     renderer.close_group(\u001b[33m'\u001b[39m\u001b[33mfigure\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3261\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/axes/_base.py:3216\u001b[39m, in \u001b[36m_AxesBase.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[32m   3214\u001b[39m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m), artists_rasterized, renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3216\u001b[39m \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3219\u001b[39m renderer.close_group(\u001b[33m'\u001b[39m\u001b[33maxes\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3220\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/axis.py:1405\u001b[39m, in \u001b[36mAxis.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   1402\u001b[39m renderer.open_group(\u001b[34m__name__\u001b[39m, gid=\u001b[38;5;28mself\u001b[39m.get_gid())\n\u001b[32m   1404\u001b[39m ticks_to_draw = \u001b[38;5;28mself\u001b[39m._update_ticks()\n\u001b[32m-> \u001b[39m\u001b[32m1405\u001b[39m tlb1, tlb2 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_ticklabel_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticks_to_draw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n\u001b[32m   1408\u001b[39m     tick.draw(renderer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/axis.py:1334\u001b[39m, in \u001b[36mAxis._get_ticklabel_bboxes\u001b[39m\u001b[34m(self, ticks, renderer)\u001b[39m\n\u001b[32m   1330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1331\u001b[39m     renderer = \u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m)._get_renderer()\n\u001b[32m   1332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick.label1.get_window_extent(renderer)\n\u001b[32m   1333\u001b[39m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick.label1.get_visible()],\n\u001b[32m-> \u001b[39m\u001b[32m1334\u001b[39m         [\u001b[43mtick\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlabel2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1335\u001b[39m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick.label2.get_visible()])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/text.py:969\u001b[39m, in \u001b[36mText.get_window_extent\u001b[39m\u001b[34m(self, renderer, dpi)\u001b[39m\n\u001b[32m    964\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    966\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwant to call \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfigure.draw_without_rendering()\u001b[39m\u001b[33m'\u001b[39m\u001b[33m first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m cbook._setattr_cm(fig, dpi=dpi):\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     bbox, info, descent = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_renderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     x, y = \u001b[38;5;28mself\u001b[39m.get_unitless_position()\n\u001b[32m    971\u001b[39m     x, y = \u001b[38;5;28mself\u001b[39m.get_transform().transform((x, y))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/text.py:373\u001b[39m, in \u001b[36mText._get_layout\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m    370\u001b[39m ys = []\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# Full vertical extent of font, including ascenders and descenders:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m _, lp_h, lp_d = \u001b[43m_get_text_metrics_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fontproperties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTeX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_usetex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m min_dy = (lp_h - lp_d) * \u001b[38;5;28mself\u001b[39m._linespacing\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lines):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/text.py:69\u001b[39m, in \u001b[36m_get_text_metrics_with_cache\u001b[39m\u001b[34m(renderer, text, fontprop, ismath, dpi)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Cached based on a copy of fontprop so that later in-place mutations of\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# the passed-in argument do not mess up the cache.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_text_metrics_with_cache_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/text.py:77\u001b[39m, in \u001b[36m_get_text_metrics_with_cache_impl\u001b[39m\u001b[34m(renderer_ref, text, fontprop, ismath, dpi)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache(\u001b[32m4096\u001b[39m)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_text_metrics_with_cache_impl\u001b[39m(\n\u001b[32m     75\u001b[39m         renderer_ref, text, fontprop, ismath, dpi):\n\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# dpi is unused, but participates in cache invalidation (via the renderer).\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrenderer_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_text_width_height_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:218\u001b[39m, in \u001b[36mRendererAgg.get_text_width_height_descent\u001b[39m\u001b[34m(self, s, prop, ismath)\u001b[39m\n\u001b[32m    214\u001b[39m     ox, oy, width, height, descent, font_image = \\\n\u001b[32m    215\u001b[39m         \u001b[38;5;28mself\u001b[39m.mathtext_parser.parse(s, \u001b[38;5;28mself\u001b[39m.dpi, prop)\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m width, height, descent\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m font = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_font\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m font.set_text(s, \u001b[32m0.0\u001b[39m, flags=get_hinting_flag())\n\u001b[32m    220\u001b[39m w, h = font.get_width_height()  \u001b[38;5;66;03m# width and height of unrotated string\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:252\u001b[39m, in \u001b[36mRendererAgg._prepare_font\u001b[39m\u001b[34m(self, font_prop)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prepare_font\u001b[39m(\u001b[38;5;28mself\u001b[39m, font_prop):\n\u001b[32m    249\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[33;03m    Get the `.FT2Font` for *font_prop*, clear its buffer, and set its size.\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     font = \u001b[43mget_font\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fontManager\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_find_fonts_by_props\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont_prop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m     font.clear()\n\u001b[32m    254\u001b[39m     size = font_prop.get_size_in_points()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/font_manager.py:1615\u001b[39m, in \u001b[36mget_font\u001b[39m\u001b[34m(font_filepaths, hinting_factor)\u001b[39m\n\u001b[32m   1612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hinting_factor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1613\u001b[39m     hinting_factor = mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33mtext.hinting_factor\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m1615\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# must be a tuple to be cached\u001b[39;49;00m\n\u001b[32m   1617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrcParams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext.kerning_factor\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# also key on the thread ID to prevent segfaults with multi-threading\u001b[39;49;00m\n\u001b[32m   1621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreading\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_ident\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/font_manager.py:1557\u001b[39m, in \u001b[36m_get_font\u001b[39m\u001b[34m(font_filepaths, hinting_factor, _kerning_factor, thread_id)\u001b[39m\n\u001b[32m   1554\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m(\u001b[32m64\u001b[39m)\n\u001b[32m   1555\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_font\u001b[39m(font_filepaths, hinting_factor, *, _kerning_factor, thread_id):\n\u001b[32m   1556\u001b[39m     first_fontpath, *rest = font_filepaths\n\u001b[32m-> \u001b[39m\u001b[32m1557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mft2font\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFT2Font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfirst_fontpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_fallback_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[43m            \u001b[49m\u001b[43mft2font\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFT2Font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_kerning_factor\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrest\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_kerning_factor\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/core/formatters.py:402\u001b[39m, in \u001b[36mBaseFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[32m    404\u001b[39m method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/core/pylabtools.py:170\u001b[39m, in \u001b[36mprint_figure\u001b[39m\u001b[34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[32m    168\u001b[39m     FigureCanvasBase(fig)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m data = bytes_io.getvalue()\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fmt == \u001b[33m'\u001b[39m\u001b[33msvg\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/backend_bases.py:2155\u001b[39m, in \u001b[36mFigureCanvasBase.print_figure\u001b[39m\u001b[34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[39m\n\u001b[32m   2152\u001b[39m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[32m   2153\u001b[39m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[32m   2154\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[33m\"\u001b[39m\u001b[33m_draw_disabled\u001b[39m\u001b[33m\"\u001b[39m, nullcontext)():\n\u001b[32m-> \u001b[39m\u001b[32m2155\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2156\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[32m   2157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches == \u001b[33m\"\u001b[39m\u001b[33mtight\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/artist.py:94\u001b[39m, in \u001b[36m_finalize_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdraw_wrapper\u001b[39m(artist, renderer, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     result = \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m renderer._rasterizing:\n\u001b[32m     96\u001b[39m         renderer.stop_rasterizing()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/figure.py:3257\u001b[39m, in \u001b[36mFigure.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3254\u001b[39m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[32m   3256\u001b[39m     \u001b[38;5;28mself\u001b[39m.patch.draw(renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3257\u001b[39m     \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3260\u001b[39m     renderer.close_group(\u001b[33m'\u001b[39m\u001b[33mfigure\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3261\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/axes/_base.py:3216\u001b[39m, in \u001b[36m_AxesBase.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[32m   3214\u001b[39m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m), artists_rasterized, renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3216\u001b[39m \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3219\u001b[39m renderer.close_group(\u001b[33m'\u001b[39m\u001b[33maxes\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3220\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/axis.py:1405\u001b[39m, in \u001b[36mAxis.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   1402\u001b[39m renderer.open_group(\u001b[34m__name__\u001b[39m, gid=\u001b[38;5;28mself\u001b[39m.get_gid())\n\u001b[32m   1404\u001b[39m ticks_to_draw = \u001b[38;5;28mself\u001b[39m._update_ticks()\n\u001b[32m-> \u001b[39m\u001b[32m1405\u001b[39m tlb1, tlb2 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_ticklabel_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticks_to_draw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n\u001b[32m   1408\u001b[39m     tick.draw(renderer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/axis.py:1334\u001b[39m, in \u001b[36mAxis._get_ticklabel_bboxes\u001b[39m\u001b[34m(self, ticks, renderer)\u001b[39m\n\u001b[32m   1330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1331\u001b[39m     renderer = \u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m)._get_renderer()\n\u001b[32m   1332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick.label1.get_window_extent(renderer)\n\u001b[32m   1333\u001b[39m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick.label1.get_visible()],\n\u001b[32m-> \u001b[39m\u001b[32m1334\u001b[39m         [\u001b[43mtick\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlabel2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1335\u001b[39m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick.label2.get_visible()])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/text.py:969\u001b[39m, in \u001b[36mText.get_window_extent\u001b[39m\u001b[34m(self, renderer, dpi)\u001b[39m\n\u001b[32m    964\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    966\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwant to call \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfigure.draw_without_rendering()\u001b[39m\u001b[33m'\u001b[39m\u001b[33m first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m cbook._setattr_cm(fig, dpi=dpi):\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     bbox, info, descent = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_renderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     x, y = \u001b[38;5;28mself\u001b[39m.get_unitless_position()\n\u001b[32m    971\u001b[39m     x, y = \u001b[38;5;28mself\u001b[39m.get_transform().transform((x, y))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/text.py:373\u001b[39m, in \u001b[36mText._get_layout\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m    370\u001b[39m ys = []\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# Full vertical extent of font, including ascenders and descenders:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m _, lp_h, lp_d = \u001b[43m_get_text_metrics_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fontproperties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTeX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_usetex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m min_dy = (lp_h - lp_d) * \u001b[38;5;28mself\u001b[39m._linespacing\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lines):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/text.py:69\u001b[39m, in \u001b[36m_get_text_metrics_with_cache\u001b[39m\u001b[34m(renderer, text, fontprop, ismath, dpi)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Cached based on a copy of fontprop so that later in-place mutations of\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# the passed-in argument do not mess up the cache.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_text_metrics_with_cache_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/text.py:77\u001b[39m, in \u001b[36m_get_text_metrics_with_cache_impl\u001b[39m\u001b[34m(renderer_ref, text, fontprop, ismath, dpi)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache(\u001b[32m4096\u001b[39m)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_text_metrics_with_cache_impl\u001b[39m(\n\u001b[32m     75\u001b[39m         renderer_ref, text, fontprop, ismath, dpi):\n\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# dpi is unused, but participates in cache invalidation (via the renderer).\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrenderer_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_text_width_height_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:218\u001b[39m, in \u001b[36mRendererAgg.get_text_width_height_descent\u001b[39m\u001b[34m(self, s, prop, ismath)\u001b[39m\n\u001b[32m    214\u001b[39m     ox, oy, width, height, descent, font_image = \\\n\u001b[32m    215\u001b[39m         \u001b[38;5;28mself\u001b[39m.mathtext_parser.parse(s, \u001b[38;5;28mself\u001b[39m.dpi, prop)\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m width, height, descent\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m font = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_font\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m font.set_text(s, \u001b[32m0.0\u001b[39m, flags=get_hinting_flag())\n\u001b[32m    220\u001b[39m w, h = font.get_width_height()  \u001b[38;5;66;03m# width and height of unrotated string\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:252\u001b[39m, in \u001b[36mRendererAgg._prepare_font\u001b[39m\u001b[34m(self, font_prop)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prepare_font\u001b[39m(\u001b[38;5;28mself\u001b[39m, font_prop):\n\u001b[32m    249\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[33;03m    Get the `.FT2Font` for *font_prop*, clear its buffer, and set its size.\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     font = \u001b[43mget_font\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fontManager\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_find_fonts_by_props\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont_prop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m     font.clear()\n\u001b[32m    254\u001b[39m     size = font_prop.get_size_in_points()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/font_manager.py:1615\u001b[39m, in \u001b[36mget_font\u001b[39m\u001b[34m(font_filepaths, hinting_factor)\u001b[39m\n\u001b[32m   1612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hinting_factor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1613\u001b[39m     hinting_factor = mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33mtext.hinting_factor\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m1615\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# must be a tuple to be cached\u001b[39;49;00m\n\u001b[32m   1617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrcParams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext.kerning_factor\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# also key on the thread ID to prevent segfaults with multi-threading\u001b[39;49;00m\n\u001b[32m   1621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreading\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_ident\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/matplotlib/font_manager.py:1557\u001b[39m, in \u001b[36m_get_font\u001b[39m\u001b[34m(font_filepaths, hinting_factor, _kerning_factor, thread_id)\u001b[39m\n\u001b[32m   1554\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m(\u001b[32m64\u001b[39m)\n\u001b[32m   1555\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_font\u001b[39m(font_filepaths, hinting_factor, *, _kerning_factor, thread_id):\n\u001b[32m   1556\u001b[39m     first_fontpath, *rest = font_filepaths\n\u001b[32m-> \u001b[39m\u001b[32m1557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mft2font\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFT2Font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfirst_fontpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_fallback_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[43m            \u001b[49m\u001b[43mft2font\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFT2Font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_kerning_factor\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrest\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_kerning_factor\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x2800 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================\n",
    "# 10. 어텐션 시각화\n",
    "# =========================================\n",
    "\n",
    "def display_attention(sentence, translation, attention, n_heads=8, n_rows=4, n_cols=2):\n",
    "    \"\"\"어텐션 맵을 시각화합니다.\"\"\"\n",
    "    assert n_rows * n_cols == n_heads\n",
    "\n",
    "    font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "    font_prop = fm.FontProperties(fname=font_path, size=8)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 28))\n",
    "\n",
    "    sentence_tokens = sentence.split()\n",
    "    translation_tokens = translation.split()\n",
    "\n",
    "    # 디코더-인코더 어텐션의 마지막 레이어 사용\n",
    "    attn = attention[-1]  # shape: (B, H, TgtL, SrcL)\n",
    "\n",
    "    for i in range(n_heads):\n",
    "        ax = fig.add_subplot(n_rows, n_cols, i + 1)\n",
    "        _attention = attn.squeeze(0)[i].detach().cpu().numpy()\n",
    "        src_len = len(sentence_tokens)\n",
    "        tgt_len = len(translation_tokens)\n",
    "        cax = ax.matshow(_attention[:, :src_len], cmap='viridis',\n",
    "                         extent=[-0.5, src_len - 0.5, tgt_len - 0.5, -0.5])\n",
    "        ax.set_xticks(range(src_len))\n",
    "        ax.set_yticks(range(tgt_len))\n",
    "        ax.set_xticklabels(sentence_tokens, rotation=90, fontproperties=font_prop, ha='center', va='center')\n",
    "        ax.set_yticklabels(translation_tokens, fontproperties=font_prop, ha='right', va='center')\n",
    "        ax.tick_params(labelsize=8, pad=15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "display_attention(src, translation, attention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4073f5-b7b6-4d9f-80e0-c2f399f18f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
